{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used to manipulate data and describe the data with plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO DO\n",
    "\n",
    "I need to add the game number of that season as a column in order to take of the first n games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVP\n",
    "- created two data sets\n",
    "    - game by game statistics (each row accounts for a single game)\n",
    "    - aggregated statistics (each row accounts for all games up to that game)\n",
    "- feature selection process that produced similar but slightly worse predictions\n",
    "- xgboost model predicting with 58% accuracy\n",
    "\n",
    "Post MVP plans\n",
    "- make predicitons on a single season\n",
    "- identify optimal number of games for statistics to aggregate\n",
    "- neural net for predictions\n",
    "- allow game by game predictions usable with gui or interface of some sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Season Predictions\n",
    "For this experiment I am going to be using the best performing model (XGBoost) with optimal parameters to make predictions on a single season. The test set is going to be the 2019 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing aggregate data and dropping unnamed\n",
    "df = pd.read_csv('data/aggregate_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convering date column from object to datetime\n",
    "df.Date = pd.to_datetime(df.Date,format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.Date.dt.year==2019)&(df.home_team=='NYA')].head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','game_in_series'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_team_score</th>\n",
       "      <th>home_at_bats</th>\n",
       "      <th>home_hits</th>\n",
       "      <th>home_doubles</th>\n",
       "      <th>home_triples</th>\n",
       "      <th>home_hrs</th>\n",
       "      <th>home_rbi</th>\n",
       "      <th>home_sh</th>\n",
       "      <th>home_sf</th>\n",
       "      <th>home_hbp</th>\n",
       "      <th>home_walk</th>\n",
       "      <th>home_int_walk</th>\n",
       "      <th>home_so</th>\n",
       "      <th>home_sb</th>\n",
       "      <th>home_cs</th>\n",
       "      <th>home_gidp</th>\n",
       "      <th>home_catch_interference</th>\n",
       "      <th>home_left_on_base</th>\n",
       "      <th>home_pitchers_used</th>\n",
       "      <th>home_pitch_earned_runs</th>\n",
       "      <th>home_team_earned_runs</th>\n",
       "      <th>home_pitch_wild_pitches</th>\n",
       "      <th>home_pitch_balks</th>\n",
       "      <th>home_def_putouts</th>\n",
       "      <th>home_def_assists</th>\n",
       "      <th>home_def_errors</th>\n",
       "      <th>home_def_passed_balls</th>\n",
       "      <th>home_def_double_plays</th>\n",
       "      <th>home_def_triple_plays</th>\n",
       "      <th>home_win_loss</th>\n",
       "      <th>home_OBP</th>\n",
       "      <th>home_AVG</th>\n",
       "      <th>home_singles</th>\n",
       "      <th>home_SLG</th>\n",
       "      <th>home_BABIP</th>\n",
       "      <th>home_ISO</th>\n",
       "      <th>home_PASO</th>\n",
       "      <th>home_total_bases</th>\n",
       "      <th>home_runs_created</th>\n",
       "      <th>home_wOBA</th>\n",
       "      <th>game_of_season_home</th>\n",
       "      <th>away_team_score</th>\n",
       "      <th>away_at_bats</th>\n",
       "      <th>away_hits</th>\n",
       "      <th>away_doubles</th>\n",
       "      <th>away_triples</th>\n",
       "      <th>away_hrs</th>\n",
       "      <th>away_rbi</th>\n",
       "      <th>away_sh</th>\n",
       "      <th>away_sf</th>\n",
       "      <th>away_hbp</th>\n",
       "      <th>away_walk</th>\n",
       "      <th>away_int_walk</th>\n",
       "      <th>away_so</th>\n",
       "      <th>away_sb</th>\n",
       "      <th>away_cs</th>\n",
       "      <th>away_gidp</th>\n",
       "      <th>away_catch_interference</th>\n",
       "      <th>away_left_on_base</th>\n",
       "      <th>away_pitchers_used</th>\n",
       "      <th>away_pitch_earned_runs</th>\n",
       "      <th>away_team_earned_runs</th>\n",
       "      <th>away_pitch_wild_pitches</th>\n",
       "      <th>away_pitch_balks</th>\n",
       "      <th>away_def_putouts</th>\n",
       "      <th>away_def_assists</th>\n",
       "      <th>away_def_errors</th>\n",
       "      <th>away_def_passed_balls</th>\n",
       "      <th>away_def_double_plays</th>\n",
       "      <th>away_def_triple_plays</th>\n",
       "      <th>away_win_loss</th>\n",
       "      <th>away_OBP</th>\n",
       "      <th>away_AVG</th>\n",
       "      <th>away_singles</th>\n",
       "      <th>away_SLG</th>\n",
       "      <th>away_BABIP</th>\n",
       "      <th>away_ISO</th>\n",
       "      <th>away_PASO</th>\n",
       "      <th>away_total_bases</th>\n",
       "      <th>away_runs_created</th>\n",
       "      <th>away_wOBA</th>\n",
       "      <th>game_of_season_away</th>\n",
       "      <th>home_outcome</th>\n",
       "      <th>away_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>NYN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>COL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>MIL</td>\n",
       "      <td>CIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>SFN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>LAN</td>\n",
       "      <td>WAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48563</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>DET</td>\n",
       "      <td>CHA</td>\n",
       "      <td>4.393750</td>\n",
       "      <td>34.381250</td>\n",
       "      <td>8.99375</td>\n",
       "      <td>1.612500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.131250</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>2.356250</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>9.606250</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>4.318750</td>\n",
       "      <td>4.793750</td>\n",
       "      <td>4.787500</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>26.318750</td>\n",
       "      <td>9.437500</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.308682</td>\n",
       "      <td>0.256513</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>0.406390</td>\n",
       "      <td>0.324657</td>\n",
       "      <td>0.149877</td>\n",
       "      <td>4.136388</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>4.699443</td>\n",
       "      <td>0.315905</td>\n",
       "      <td>161.0</td>\n",
       "      <td>3.618750</td>\n",
       "      <td>34.487500</td>\n",
       "      <td>8.287500</td>\n",
       "      <td>1.818750</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>3.456250</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.425000</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>9.918750</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>4.587500</td>\n",
       "      <td>5.206250</td>\n",
       "      <td>5.193750</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>26.718750</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.286314</td>\n",
       "      <td>0.234660</td>\n",
       "      <td>5.293750</td>\n",
       "      <td>0.379340</td>\n",
       "      <td>0.300106</td>\n",
       "      <td>0.144680</td>\n",
       "      <td>3.861421</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>4.207533</td>\n",
       "      <td>0.293725</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48564</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>MIN</td>\n",
       "      <td>KCA</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>33.931677</td>\n",
       "      <td>8.36646</td>\n",
       "      <td>1.726708</td>\n",
       "      <td>0.242236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.037267</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.254658</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>2.813665</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>8.683230</td>\n",
       "      <td>0.726708</td>\n",
       "      <td>0.242236</td>\n",
       "      <td>0.701863</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>6.515528</td>\n",
       "      <td>4.211180</td>\n",
       "      <td>5.093168</td>\n",
       "      <td>5.093168</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>26.385093</td>\n",
       "      <td>9.329193</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.360248</td>\n",
       "      <td>0.302681</td>\n",
       "      <td>0.242305</td>\n",
       "      <td>5.397516</td>\n",
       "      <td>0.392268</td>\n",
       "      <td>0.295905</td>\n",
       "      <td>0.149962</td>\n",
       "      <td>4.453711</td>\n",
       "      <td>13.577640</td>\n",
       "      <td>4.407290</td>\n",
       "      <td>0.307124</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5.807453</td>\n",
       "      <td>35.403727</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>1.968944</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.888199</td>\n",
       "      <td>5.602484</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>0.254658</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>3.260870</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>8.236025</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.627329</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>6.913043</td>\n",
       "      <td>4.223602</td>\n",
       "      <td>4.192547</td>\n",
       "      <td>4.192547</td>\n",
       "      <td>0.440994</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>27.111801</td>\n",
       "      <td>8.677019</td>\n",
       "      <td>0.683230</td>\n",
       "      <td>0.093168</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.627329</td>\n",
       "      <td>0.332489</td>\n",
       "      <td>0.264235</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>0.483901</td>\n",
       "      <td>0.292951</td>\n",
       "      <td>0.219666</td>\n",
       "      <td>5.045172</td>\n",
       "      <td>17.490683</td>\n",
       "      <td>6.157451</td>\n",
       "      <td>0.356767</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48565</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>OAK</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.662500</td>\n",
       "      <td>33.987500</td>\n",
       "      <td>8.06875</td>\n",
       "      <td>1.568750</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>4.487500</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>3.606250</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>9.775000</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>6.662500</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>4.943750</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>26.650000</td>\n",
       "      <td>9.193750</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.304135</td>\n",
       "      <td>0.230968</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>0.413480</td>\n",
       "      <td>0.279212</td>\n",
       "      <td>0.182512</td>\n",
       "      <td>3.802788</td>\n",
       "      <td>14.412500</td>\n",
       "      <td>4.813185</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>161.0</td>\n",
       "      <td>5.231250</td>\n",
       "      <td>34.350000</td>\n",
       "      <td>8.575000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>3.568750</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>8.262500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.693750</td>\n",
       "      <td>4.356250</td>\n",
       "      <td>3.962500</td>\n",
       "      <td>3.962500</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>27.150000</td>\n",
       "      <td>9.087500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.320794</td>\n",
       "      <td>0.244032</td>\n",
       "      <td>5.043750</td>\n",
       "      <td>0.439480</td>\n",
       "      <td>0.276033</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>4.839062</td>\n",
       "      <td>15.425000</td>\n",
       "      <td>5.235853</td>\n",
       "      <td>0.335078</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48566</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>NYA</td>\n",
       "      <td>TEX</td>\n",
       "      <td>4.993789</td>\n",
       "      <td>34.217391</td>\n",
       "      <td>8.47205</td>\n",
       "      <td>1.832298</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>1.385093</td>\n",
       "      <td>4.726708</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>0.267081</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>3.291925</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>9.763975</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>6.577640</td>\n",
       "      <td>4.099379</td>\n",
       "      <td>5.043478</td>\n",
       "      <td>5.012422</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>26.627329</td>\n",
       "      <td>8.465839</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.068323</td>\n",
       "      <td>0.888199</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.310396</td>\n",
       "      <td>0.241520</td>\n",
       "      <td>5.105590</td>\n",
       "      <td>0.422123</td>\n",
       "      <td>0.295096</td>\n",
       "      <td>0.180603</td>\n",
       "      <td>3.919005</td>\n",
       "      <td>14.757764</td>\n",
       "      <td>4.942092</td>\n",
       "      <td>0.322698</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5.850932</td>\n",
       "      <td>34.490683</td>\n",
       "      <td>9.254658</td>\n",
       "      <td>1.801242</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>1.894410</td>\n",
       "      <td>5.608696</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>0.204969</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>3.527950</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>8.844720</td>\n",
       "      <td>0.341615</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.701863</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>6.434783</td>\n",
       "      <td>4.354037</td>\n",
       "      <td>4.267081</td>\n",
       "      <td>4.267081</td>\n",
       "      <td>0.341615</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>26.739130</td>\n",
       "      <td>8.316770</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.080745</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639752</td>\n",
       "      <td>0.333478</td>\n",
       "      <td>0.263322</td>\n",
       "      <td>5.453416</td>\n",
       "      <td>0.481912</td>\n",
       "      <td>0.302061</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>4.379459</td>\n",
       "      <td>16.950311</td>\n",
       "      <td>5.995393</td>\n",
       "      <td>0.356419</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>TBA</td>\n",
       "      <td>TOR</td>\n",
       "      <td>4.459627</td>\n",
       "      <td>33.900621</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>4.279503</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.273292</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>9.347826</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>0.664596</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>6.186335</td>\n",
       "      <td>4.645963</td>\n",
       "      <td>4.745342</td>\n",
       "      <td>4.745342</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>26.670807</td>\n",
       "      <td>9.273292</td>\n",
       "      <td>0.590062</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.295169</td>\n",
       "      <td>0.228542</td>\n",
       "      <td>4.695652</td>\n",
       "      <td>0.414308</td>\n",
       "      <td>0.269658</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>4.179982</td>\n",
       "      <td>14.478261</td>\n",
       "      <td>4.793575</td>\n",
       "      <td>0.311682</td>\n",
       "      <td>162.0</td>\n",
       "      <td>4.757764</td>\n",
       "      <td>34.732919</td>\n",
       "      <td>8.807453</td>\n",
       "      <td>1.788820</td>\n",
       "      <td>0.180124</td>\n",
       "      <td>1.341615</td>\n",
       "      <td>4.515528</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.453416</td>\n",
       "      <td>3.360248</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>9.211180</td>\n",
       "      <td>0.577640</td>\n",
       "      <td>0.229814</td>\n",
       "      <td>0.708075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.975155</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>3.689441</td>\n",
       "      <td>3.664596</td>\n",
       "      <td>0.360248</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>27.322981</td>\n",
       "      <td>8.757764</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.099379</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.320677</td>\n",
       "      <td>0.249918</td>\n",
       "      <td>5.496894</td>\n",
       "      <td>0.426703</td>\n",
       "      <td>0.301846</td>\n",
       "      <td>0.176785</td>\n",
       "      <td>4.392976</td>\n",
       "      <td>14.981366</td>\n",
       "      <td>5.069367</td>\n",
       "      <td>0.330032</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48568 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date away_team home_team  home_team_score  home_at_bats  home_hits  home_doubles  home_triples  home_hrs  home_rbi   home_sh   home_sf  home_hbp  home_walk  home_int_walk   home_so   home_sb   home_cs  home_gidp  home_catch_interference  home_left_on_base  home_pitchers_used  home_pitch_earned_runs  home_team_earned_runs  home_pitch_wild_pitches  home_pitch_balks  home_def_putouts  home_def_assists  home_def_errors  home_def_passed_balls  home_def_double_plays  home_def_triple_plays  home_win_loss  home_OBP  home_AVG  home_singles  home_SLG  home_BABIP  home_ISO  home_PASO  home_total_bases  home_runs_created  home_wOBA  game_of_season_home  away_team_score  away_at_bats  away_hits  away_doubles  away_triples  away_hrs  away_rbi   away_sh   away_sf  away_hbp  away_walk  away_int_walk   away_so   away_sb   away_cs  away_gidp  away_catch_interference  away_left_on_base  away_pitchers_used  away_pitch_earned_runs  away_team_earned_runs  away_pitch_wild_pitches  \\\n",
       "0     2000-03-30       NYN       CHN              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN               NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN   \n",
       "1     2000-04-03       COL       ATL              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN               NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN   \n",
       "2     2000-04-03       MIL       CIN              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN               NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN   \n",
       "3     2000-04-03       SFN       MIA              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN               NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN   \n",
       "4     2000-04-03       LAN       WAS              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN               NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0              NaN           NaN        NaN           NaN           NaN       NaN       NaN       NaN       NaN       NaN        NaN            NaN       NaN       NaN       NaN        NaN                      NaN                NaN                 NaN                     NaN                    NaN                      NaN   \n",
       "...          ...       ...       ...              ...           ...        ...           ...           ...       ...       ...       ...       ...       ...        ...            ...       ...       ...       ...        ...                      ...                ...                 ...                     ...                    ...                      ...               ...               ...               ...              ...                    ...                    ...                    ...            ...       ...       ...           ...       ...         ...       ...        ...               ...                ...        ...                  ...              ...           ...        ...           ...           ...       ...       ...       ...       ...       ...        ...            ...       ...       ...       ...        ...                      ...                ...                 ...                     ...                    ...                      ...   \n",
       "48563 2019-09-29       DET       CHA         4.393750     34.381250    8.99375      1.612500      0.125000  1.131250  4.200000  0.225000  0.200000  0.393750   2.356250       0.081250  9.606250  0.393750  0.175000   0.706250                 0.006250           6.675000            4.318750                4.793750               4.787500                 0.443750          0.031250         26.318750          9.437500         0.731250               0.081250               1.050000                0.00625       0.443750  0.308682  0.256513      6.125000  0.406390    0.324657  0.149877   4.136388         14.250000           4.699443   0.315905                161.0         3.618750     34.487500   8.287500      1.818750      0.256250  0.918750  3.456250  0.056250  0.262500  0.300000   2.425000       0.087500  9.918750  0.350000  0.125000   0.662500                 0.000000           6.656250            4.587500                5.206250               5.193750                 0.406250   \n",
       "48564 2019-09-29       MIN       KCA         4.260870     33.931677    8.36646      1.726708      0.242236  1.000000  4.037267  0.149068  0.254658  0.366460   2.813665       0.105590  8.683230  0.726708  0.242236   0.701863                 0.018634           6.515528            4.211180                5.093168               5.093168                 0.366460          0.031056         26.385093          9.329193         0.447205               0.062112               0.937888                0.00000       0.360248  0.302681  0.242305      5.397516  0.392268    0.295905  0.149962   4.453711         13.577640           4.407290   0.307124                162.0         5.807453     35.403727   9.571429      1.968944      0.142857  1.888199  5.602484  0.062112  0.254658  0.496894   3.260870       0.130435  8.236025  0.173913  0.130435   0.627329                 0.018634           6.913043            4.223602                4.192547               4.192547                 0.440994   \n",
       "48565 2019-09-29       OAK       SEA         4.662500     33.987500    8.06875      1.568750      0.175000  1.475000  4.487500  0.081250  0.225000  0.350000   3.606250       0.043750  9.775000  0.706250  0.287500   0.518750                 0.012500           6.662500            4.300000                4.950000               4.943750                 0.437500          0.025000         26.650000          9.193750         0.818750               0.037500               0.900000                0.00000       0.412500  0.304135  0.230968      4.850000  0.413480    0.279212  0.182512   3.802788         14.412500           4.813185   0.315740                161.0         5.231250     34.350000   8.575000      1.800000      0.143750  1.587500  4.950000  0.043750  0.225000  0.543750   3.568750       0.106250  8.262500  0.300000  0.131250   0.862500                 0.000000           6.693750            4.356250                3.962500               3.962500                 0.443750   \n",
       "48566 2019-09-29       NYA       TEX         4.993789     34.217391    8.47205      1.832298      0.149068  1.385093  4.726708  0.105590  0.267081  0.409938   3.291925       0.111801  9.763975  0.795031  0.236025   0.596273                 0.012422           6.577640            4.099379                5.043478               5.012422                 0.422360          0.018634         26.627329          8.465839         0.652174               0.068323               0.888199                0.00000       0.478261  0.310396  0.241520      5.105590  0.422123    0.295096  0.180603   3.919005         14.757764           4.942092   0.322698                162.0         5.850932     34.490683   9.254658      1.801242      0.105590  1.894410  5.608696  0.062112  0.204969  0.304348   3.527950       0.111801  8.844720  0.341615  0.136646   0.701863                 0.006211           6.434783            4.354037                4.267081               4.267081                 0.341615   \n",
       "48567 2019-09-29       TBA       TOR         4.459627     33.900621    8.00000      1.652174      0.130435  1.521739  4.279503  0.086957  0.173913  0.273292   3.142857       0.062112  9.347826  0.304348  0.124224   0.664596                 0.012422           6.186335            4.645963                4.745342               4.745342                 0.434783          0.037267         26.670807          9.273292         0.590062               0.055901               0.869565                0.00000       0.409938  0.295169  0.228542      4.695652  0.414308    0.269658  0.185767   4.179982         14.478261           4.793575   0.311682                162.0         4.757764     34.732919   8.807453      1.788820      0.180124  1.341615  4.515528  0.049689  0.211180  0.453416   3.360248       0.124224  9.211180  0.577640  0.229814   0.708075                 0.000000           6.975155            4.714286                3.689441               3.664596                 0.360248   \n",
       "\n",
       "       away_pitch_balks  away_def_putouts  away_def_assists  away_def_errors  away_def_passed_balls  away_def_double_plays  away_def_triple_plays  away_win_loss  away_OBP  away_AVG  away_singles  away_SLG  away_BABIP  away_ISO  away_PASO  away_total_bases  away_runs_created  away_wOBA  game_of_season_away  home_outcome  away_outcome  \n",
       "0                   NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0             0             1  \n",
       "1                   NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0             1             0  \n",
       "2                   NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0            -1            -1  \n",
       "3                   NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0             1             0  \n",
       "4                   NaN               NaN               NaN              NaN                    NaN                    NaN                    NaN            NaN       NaN       NaN           NaN       NaN         NaN       NaN        NaN               NaN                NaN        NaN                  1.0             0             1  \n",
       "...                 ...               ...               ...              ...                    ...                    ...                    ...            ...       ...       ...           ...       ...         ...       ...        ...               ...                ...        ...                  ...           ...           ...  \n",
       "48563          0.043750         26.718750          9.031250         0.681250               0.100000               0.787500               0.000000       0.293750  0.286314  0.234660      5.293750  0.379340    0.300106  0.144680   3.861421         13.375000           4.207533   0.293725                161.0             1             0  \n",
       "48564          0.031056         27.111801          8.677019         0.683230               0.093168               0.801242               0.012422       0.627329  0.332489  0.264235      5.571429  0.483901    0.292951  0.219666   5.045172         17.490683           6.157451   0.356767                162.0             1             0  \n",
       "48565          0.025000         27.150000          9.087500         0.500000               0.118750               0.768750               0.000000       0.606250  0.320794  0.244032      5.043750  0.439480    0.276033  0.195448   4.839062         15.425000           5.235853   0.335078                161.0             1             0  \n",
       "48566          0.031056         26.739130          8.316770         0.621118               0.080745               0.826087               0.000000       0.639752  0.333478  0.263322      5.453416  0.481912    0.302061  0.218590   4.379459         16.950311           5.995393   0.356419                162.0             1             0  \n",
       "48567          0.043478         27.322981          8.757764         0.540373               0.099379               0.801242               0.000000       0.596273  0.320677  0.249918      5.496894  0.426703    0.301846  0.176785   4.392976         14.981366           5.069367   0.330032                162.0             1             0  \n",
       "\n",
       "[48568 rows x 87 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train test split manually\n",
    "train_set = df[(df.Date.dt.year != 2019)]\n",
    "test_set = df[(df.Date.dt.year == 2019)]\n",
    "\n",
    "# going to order test set because if used in real time would only have games coming in order of date\n",
    "test_set.sort_values(by=['Date'],inplace=True)\n",
    "\n",
    "# going to drop the first 10 games of each season from train\n",
    "train_set = train_set[(df.game_of_season_home > 10)&(df.game_of_season_away > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating x and y from train (all games not in 2019)\n",
    "X_train = train_set.drop(columns=['home_outcome','away_outcome'])\n",
    "y_train = train_set['home_outcome']\n",
    "\n",
    "# creating x and y from test (all 2019 games)\n",
    "X_test = test_set.drop(columns=['home_outcome','away_outcome'])\n",
    "y_test = test_set['home_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=2,\n",
       "              n_estimators=300, objective='multi:softprob')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                 learning_rate = 0.01,\n",
    "                                 max_depth = 5,\n",
    "                                 min_child_weight = 2,\n",
    "                                 n_estimators = 300)\n",
    "# dropping 3 columns that are not used for prediction\n",
    "xgb_model.fit(X_train.drop(columns=['home_team','away_team','Date']),\n",
    "              y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_final.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(xgb_model,\"xgb_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.607177\n",
      "Test Accuracy: 0.581960\n"
     ]
    }
   ],
   "source": [
    "xgb_model_predictions_train = xgb_model.predict(X_train.drop(columns=['home_team','away_team','Date']))\n",
    "xgb_model_predictions_test = xgb_model.predict(X_test.drop(columns=['home_team','away_team','Date']))\n",
    "train_acc = accuracy_score(y_train, xgb_model_predictions_train)\n",
    "test_acc = accuracy_score(y_test, xgb_model_predictions_test)\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games right: 1413\n",
      "Number of games wrong: 1015\n",
      "Best rolling game streak: 0.74\n",
      "Season Accuracy: 0.5819604612850082\n"
     ]
    }
   ],
   "source": [
    "# looking at when we are predicting the best\n",
    "# accuracy over whole season\n",
    "accuracy_whole = 0\n",
    "# past games right or wrongs\n",
    "game_preds = []\n",
    "# list to hold game rolling accuracy throuhgout whole season to see how we do as season goes on\n",
    "accuracy_rolling_season = []\n",
    "# number of games seen\n",
    "num_of_games = 0\n",
    "# correct predictions\n",
    "num_right = 0\n",
    "# wrong predictions\n",
    "num_wrong = 0\n",
    "# number of games for rolling\n",
    "rolling_number = 50\n",
    "\n",
    "for true,pred in zip(y_test,xgb_model_predictions_test):\n",
    "    # after seeing rolling number of games\n",
    "    if num_of_games > rolling_number:\n",
    "        # get rid of least recent game, using append so most recent game at end\n",
    "        game_preds = game_preds[1:]\n",
    "    # every period of rolling games calculate the rolling accuracy\n",
    "    if num_of_games % rolling_number == 0:\n",
    "        # calcuate rolling game accuracy and append to season list\n",
    "        accuracy_rolling_season.append(sum(game_preds)/rolling_number)\n",
    "    # one more game seen\n",
    "    num_of_games +=1\n",
    "    # correct prediction\n",
    "    if pred == true:\n",
    "        num_right += 1\n",
    "        game_preds.append(1)\n",
    "    # wrong prediction\n",
    "    else:\n",
    "        num_wrong +=1\n",
    "        game_preds.append(0)\n",
    "accuracy_whole = num_right/num_of_games\n",
    "\n",
    "print('Number of games right: {}'.format(num_right))\n",
    "print('Number of games wrong: {}'.format(num_wrong))\n",
    "print('Best rolling game streak: {}'.format(max(accuracy_rolling_season)))\n",
    "print('Season Accuracy: {}'.format(accuracy_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(accuracy_rolling_season,color='red')\n",
    "ax.set_xlabel('Sets of 50 Games Seen')\n",
    "ax.set_ylabel('Accuracy Over 50 Games')\n",
    "ax.set_yticks(np.linspace(0,1,11))\n",
    "ax.set_xticks(range(0,round(num_of_games/50),5))\n",
    "ax.set_title('Accuracy over Season (50 Game Splits)')\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Game Number Buffer\n",
    "When using aggregated statistics it is useful to not predict on the games at the start of the season as the aggregated statistics have not had enought time to really show how well that team performs. Allowing a 10 game buffer would allow us to build up the statistics and then by the 11th game we have a much better idea on how each team will perform allowing for better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_prediction(buffer):\n",
    "    # creating train test split manually\n",
    "    X = df.drop(columns=['home_outcome','away_outcome'])\n",
    "    y = df.home_outcome\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=49)\n",
    "    # get rid of games in train before buffer number\n",
    "    # combine x and y so they dont get mixed\n",
    "    train = pd.concat([X_train,y_train],axis=1)\n",
    "    # get rid of games before buffer game number\n",
    "    train = train[(train.game_of_season_home>buffer)]\n",
    "    # make x and y train\n",
    "    X_train = train.drop(columns='home_outcome')\n",
    "    y_train = train.home_outcome\n",
    "    \n",
    "    \n",
    "    #run model\n",
    "    xgb_model_buffer = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                                 learning_rate = 0.01,\n",
    "                                 max_depth = 5,\n",
    "                                 min_child_weight = 2,\n",
    "                                 n_estimators = 300)\n",
    "    # dropping 3 columns that are not used for prediction\n",
    "    xgb_model_buffer.fit(X_train.drop(columns=['home_team','away_team','Date']),\n",
    "                  y_train)\n",
    "    \n",
    "    xgb_model_buffer_predictions_train = xgb_model_buffer.predict(X_train.drop(columns=['home_team','away_team','Date']))\n",
    "    xgb_model_buffer_predictions_test = xgb_model_buffer.predict(X_test.drop(columns=['home_team','away_team','Date']))\n",
    "    train_acc_buffer = accuracy_score(y_train, xgb_model_buffer_predictions_train)\n",
    "    test_acc_buffer = accuracy_score(y_test, xgb_model_buffer_predictions_test)\n",
    "    print(\"Train Accuracy: %f\" % (train_acc_buffer))\n",
    "    print(\"Test Accuracy: %f\" % (test_acc_buffer))\n",
    "    return train_acc,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.617251\n",
      "Test Accuracy: 0.559710\n",
      "Train Accuracy: 0.615278\n",
      "Test Accuracy: 0.553451\n",
      "Train Accuracy: 0.617225\n",
      "Test Accuracy: 0.557569\n",
      "Train Accuracy: 0.618915\n",
      "Test Accuracy: 0.554027\n",
      "Train Accuracy: 0.620273\n",
      "Test Accuracy: 0.553863\n",
      "Train Accuracy: 0.620214\n",
      "Test Accuracy: 0.556910\n",
      "Train Accuracy: 0.622108\n",
      "Test Accuracy: 0.552133\n"
     ]
    }
   ],
   "source": [
    "scores_per_buffer = []\n",
    "for buffer in range(0,35,5):\n",
    "    train_acc,test_acc = xg_prediction(buffer)\n",
    "    scores_per_buffer.append((train_acc,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that as we reduce the number of games seen when fitting the model the better we perfom on the training set but the worse we perform on the test set. This means that in the training set we should keep the entire dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Game Number to start predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.617251\n",
      "Test Accuracy: 0.559710\n"
     ]
    }
   ],
   "source": [
    "# creating train test split manually\n",
    "X = df.drop(columns=['home_outcome','away_outcome'])\n",
    "y = df.home_outcome\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=49)\n",
    "\n",
    "#run model\n",
    "xgb_model_buffer = xgb.XGBClassifier(objective = 'binary:logistic',\n",
    "                             learning_rate = 0.01,\n",
    "                             max_depth = 5,\n",
    "                             min_child_weight = 2,\n",
    "                             n_estimators = 300)\n",
    "# dropping 3 columns that are not used for prediction\n",
    "xgb_model_buffer.fit(X_train.drop(columns=['home_team','away_team','Date']),\n",
    "              y_train)\n",
    "\n",
    "xgb_model_buffer_predictions_train = xgb_model_buffer.predict(X_train.drop(columns=['home_team','away_team','Date']))\n",
    "xgb_model_buffer_predictions_test = xgb_model_buffer.predict(X_test.drop(columns=['home_team','away_team','Date']))\n",
    "train_acc_buffer = accuracy_score(y_train, xgb_model_buffer_predictions_train)\n",
    "test_acc_buffer = accuracy_score(y_test, xgb_model_buffer_predictions_test)\n",
    "print(\"Train Accuracy: %f\" % (train_acc_buffer))\n",
    "print(\"Test Accuracy: %f\" % (test_acc_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'game_number_of_season'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-bc72c996a87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# get rid of games before buffer game number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_number_of_season\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# make x and y train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'game_number_of_season'"
     ]
    }
   ],
   "source": [
    "\n",
    "for buffer in range(0,85,5):\n",
    "    test = pd.concat([X_test,y_test],axis=1)\n",
    "    # get rid of games before buffer game number\n",
    "    test = test[(test.game_number_of_season>buffer)]\n",
    "    print(test.shape)\n",
    "    # make x and y train\n",
    "    X_test = test.drop(columns='home_outcome_nonagg')\n",
    "    y_test = test.home_outcome_nonagg\n",
    "    xgb_model_buffer_predictions_test = xgb_model_buffer.predict(X_test.drop(columns=['home_team','away_team','Date']))\n",
    "    test_acc_buffer = accuracy_score(y_test, xgb_model_buffer_predictions_test)\n",
    "    print(\"Test Accuracy: {} with buffer {}\".format(test_acc_buffer,buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that as time goes on we greatly improve accuracy on the test set. This means that as the season goes on we have a much better chance of predicting the outcome correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets, layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='home_outcome_nonagg')\n",
    "y = df.home_outcome_nonagg\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['Date','home_team','away_team'])\n",
    "X_test = X_test.drop(columns=['Date','home_team','away_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Vanilla\n",
    "# model structure\n",
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "# 12288 = 64x64x3 = size of image\n",
    "model.add(Dense(50,input_dim=(77),activation='relu'))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# view the structure of the neural net\n",
    "#model.summary()\n",
    "\n",
    "# creating the NN, binary_cross for classification\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting the model to the train data\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                   epochs=8,\n",
    "                   verbose=1)\n",
    "# how did model perform\n",
    "score = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = tf.keras.Sequential([\n",
    "    layers.Dense(64,input_dim=(77), activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(2, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model_new.fit(X_train, y_train,\n",
    "                            epochs=8)\n",
    "\n",
    "score = model_new.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
