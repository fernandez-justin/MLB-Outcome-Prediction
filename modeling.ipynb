{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.read_csv('data/pbp_data_mvp.csv')\n",
    "df_norm.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    25777\n",
       " 0    22787\n",
       "-1        4\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_prediction(X,y):\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=99)\n",
    "\n",
    "    # Scaling is Needed for Knn\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)  \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_base = LogisticRegression(random_state=99)\n",
    "    lr_base.fit(X_train,y_train)\n",
    "    pred_lr_base = lr_base.predict(X_train)\n",
    "    score_lr_base = accuracy_score(y_train,pred_lr_base)\n",
    "    print('Logistic Regression Accuracy: {}'.format(score_lr_base))\n",
    "\n",
    "    pred_lr_base_test = lr_base.predict(X_test)\n",
    "    score_lr_base_test = accuracy_score(y_test,pred_lr_base_test)\n",
    "    print('Logistic Regression Test Accuracy: {}'.format(score_lr_base_test))\n",
    "    \n",
    "#     # KNN\n",
    "#     knn_base = KNeighborsClassifier()\n",
    "#     knn_base.fit(X_train_scaled,y_train)\n",
    "#     pred_knn_base = knn_base.predict(X_train_scaled)\n",
    "#     score_knn_base = accuracy_score(y_train,pred_knn_base)\n",
    "#     print('KNN Accuracy: {}'.format(score_knn_base))\n",
    "\n",
    "#     pred_knn_base_test = knn_base.predict(X_test_scaled)\n",
    "#     score_knn_base_test = accuracy_score(y_test,pred_knn_base_test)\n",
    "#     print('KNN Test Accuracy: {}'.format(score_knn_base_test))\n",
    "    \n",
    "    # Decision Tree\n",
    "    tree_base = DecisionTreeClassifier(max_depth=15)\n",
    "    tree_base.fit(X_train,y_train)\n",
    "    pred_tree_base = tree_base.predict(X_train)\n",
    "    score_tree_base = accuracy_score(y_train,pred_tree_base)\n",
    "    print('Tree Accuracy: {}'.format(score_tree_base))\n",
    "\n",
    "    pred_tree_base_test = tree_base.predict(X_test)\n",
    "    score_tree_base_test = accuracy_score(y_test,pred_tree_base_test)\n",
    "    print('Tree Test Accuracy: {}'.format(score_tree_base_test))\n",
    "    \n",
    "    # Random Forest\n",
    "    rand_base = RandomForestClassifier()\n",
    "    rand_base.fit(X_train,y_train)\n",
    "    pred_rand_base = rand_base.predict(X_train)\n",
    "    score_rand_base = accuracy_score(y_train,pred_rand_base)\n",
    "    print('Random Forest Accuracy: {}'.format(score_rand_base))\n",
    "\n",
    "    pred_rand_base_test = rand_base.predict(X_test)\n",
    "    score_rand_base_test = accuracy_score(y_test,pred_rand_base_test)\n",
    "    print('Random Forest Test Accuracy: {}'.format(score_rand_base_test))\n",
    "    \n",
    "    #XG Boost\n",
    "    xg_base = xgb.XGBClassifier(objecteve='binary:logistic')\n",
    "    xg_base.fit(X_train,y_train)\n",
    "    pred_xg_base = xg_base.predict(X_train)\n",
    "    score_xg_base = accuracy_score(y_train,pred_xg_base)\n",
    "    print('XGBoost Accuracy: {}'.format(score_xg_base))\n",
    "\n",
    "    pred_xg_base_test = xg_base.predict(X_test)\n",
    "    score_xg_base_test = accuracy_score(y_test,pred_xg_base_test)\n",
    "    print('XGBoost Test Accuracy: {}'.format(score_xg_base_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Data (game per game stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['forfeit_info','lf_ump_id','rf_ump_id','protest_info',\n",
    "                'date_game_completed','additional_info','save_pitch_id',\n",
    "                'game_win_rbi_batter_id','game_in_series','away_catch_interference',\n",
    "                'home_catch_interference','away_pitch_balks',\n",
    "                'home_pitch_balks','day_of_week','away_league',\n",
    "                'away_team_game_number','home_league',\n",
    "                'home_team_game_number','day_or_night','park_id',\n",
    "                'attendance','time_of_game','away_line_scores',\n",
    "                'home_line_scores','year','id','outcome',\n",
    "               'Date','away_team','home_team']\n",
    "df_norm.drop(columns=cols_to_drop,inplace=True)\n",
    "df_norm.drop(df_norm.loc[:,'hb_ump_id':'acquisition_info'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_norm.replace([np.inf,-np.inf],np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = df_norm.drop(columns='target')\n",
    "y_norm = df_norm.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prediction(X_norm,y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg_cutt_selected, X_test_agg_cutt_selected, y_train_agg_cutt_selected, y_test_agg_cutt_selected = train_test_split(X_agg_cutt[selected_wrapper],y_agg_cutt,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid_lr = { \n",
    "    'penalty': ['l2','l1','elasticnet'],\n",
    "    'C': [1e9,100,1,0.1,0.05,],\n",
    "    'max_iter':[100,500,1000]\n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid_lr, \n",
    "                         cv=10, \n",
    "                         scoring='accuracy', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train_agg_cutt_selected,y_train_agg_cutt_selected)\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_test = grid_lr.best_estimator_.predict(X_test_agg_cutt_selected)\n",
    "\n",
    "y_pred_train = grid_lr.best_estimator_.predict(X_train_agg_cutt_selected)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train_agg_cutt_selected, y_pred_train)\n",
    "test_acc = accuracy_score(y_test_agg_cutt_selected, y_pred_test)\n",
    "\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to use XG boost for now as it perfomed the best out of all combinations. This will be using the aggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg, X_test, y_train_agg, y_test = train_test_split(X_agg,y_agg,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [100,300,500],\n",
    "              'learning_rate': [1,0.1,0.05,0.01],\n",
    "              'max_depth': [3, 5, 7, 10],\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_agg, X_test_agg, y_train_agg, y_test_agg = train_test_split(X_agg,y_agg,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XG Boost\n",
    "xg_gridv1 = xgb.XGBClassifier(objecteve='binary:logistic',\n",
    "                           colsample_bytree=0.4,\n",
    "                           learning_rate=0.2,\n",
    "                           max_depth=7,\n",
    "                           min_child_weight=3,\n",
    "                            n_estimators=300)\n",
    "xg_gridv1.fit(X_train_agg,y_train_agg)\n",
    "pred_xg_gridv1 = xg_gridv1.predict(X_train_agg)\n",
    "score_xg_gridv1 = accuracy_score(y_train_agg,pred_xg_gridv1)\n",
    "print('XGBoost Accuracy: {}'.format(score_xg_gridv1))\n",
    "\n",
    "pred_xg_gridv1_test = xg_gridv1.predict(X_test_agg)\n",
    "score_xg_gridv1_test = accuracy_score(y_test_agg,pred_xg_gridv1_test)\n",
    "print('XGBoost Test Accuracy: {}'.format(score_xg_gridv1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Target Variable\n",
    "\n",
    "The way that the aggregated stats are calculated are completelty different than the stats of the normal non-aggregated table. For aggregated stats the varibales are the average of the teams statistics up until that game and not including that current game. This allows us not to have to predict the outcome of the next game (the next game the home team plays) but the outcome of the game in that row. There is no data leakage because the stats from that game have not yet been added to the aggregated stats therefore it is not included in the teams average up until that game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.read_csv('data/aggregate_data.csv')\n",
    "df_agg.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_team_score</th>\n",
       "      <th>home_at_bats</th>\n",
       "      <th>home_hits</th>\n",
       "      <th>home_doubles</th>\n",
       "      <th>home_triples</th>\n",
       "      <th>home_hrs</th>\n",
       "      <th>home_rbi</th>\n",
       "      <th>home_sh</th>\n",
       "      <th>home_sf</th>\n",
       "      <th>home_hbp</th>\n",
       "      <th>home_walk</th>\n",
       "      <th>home_int_walk</th>\n",
       "      <th>home_so</th>\n",
       "      <th>home_sb</th>\n",
       "      <th>home_cs</th>\n",
       "      <th>home_gidp</th>\n",
       "      <th>home_left_on_base</th>\n",
       "      <th>home_pitchers_used</th>\n",
       "      <th>home_pitch_earned_runs</th>\n",
       "      <th>home_team_earned_runs</th>\n",
       "      <th>home_pitch_wild_pitches</th>\n",
       "      <th>home_def_putouts</th>\n",
       "      <th>home_def_assists</th>\n",
       "      <th>home_def_errors</th>\n",
       "      <th>home_def_passed_balls</th>\n",
       "      <th>home_def_double_plays</th>\n",
       "      <th>home_def_triple_plays</th>\n",
       "      <th>home_OBP</th>\n",
       "      <th>home_AVG</th>\n",
       "      <th>home_singles</th>\n",
       "      <th>home_SLG</th>\n",
       "      <th>home_BABIP</th>\n",
       "      <th>home_ISO</th>\n",
       "      <th>home_PASO</th>\n",
       "      <th>home_total_bases</th>\n",
       "      <th>home_runs_created</th>\n",
       "      <th>home_wOBA</th>\n",
       "      <th>home_outcome</th>\n",
       "      <th>away_team_score</th>\n",
       "      <th>away_at_bats</th>\n",
       "      <th>away_hits</th>\n",
       "      <th>away_doubles</th>\n",
       "      <th>away_triples</th>\n",
       "      <th>away_hrs</th>\n",
       "      <th>away_rbi</th>\n",
       "      <th>away_sh</th>\n",
       "      <th>away_sf</th>\n",
       "      <th>away_hbp</th>\n",
       "      <th>away_walk</th>\n",
       "      <th>away_int_walk</th>\n",
       "      <th>away_so</th>\n",
       "      <th>away_sb</th>\n",
       "      <th>away_cs</th>\n",
       "      <th>away_gidp</th>\n",
       "      <th>away_left_on_base</th>\n",
       "      <th>away_pitchers_used</th>\n",
       "      <th>away_pitch_earned_runs</th>\n",
       "      <th>away_team_earned_runs</th>\n",
       "      <th>away_pitch_wild_pitches</th>\n",
       "      <th>away_def_putouts</th>\n",
       "      <th>away_def_assists</th>\n",
       "      <th>away_def_errors</th>\n",
       "      <th>away_def_passed_balls</th>\n",
       "      <th>away_def_double_plays</th>\n",
       "      <th>away_def_triple_plays</th>\n",
       "      <th>away_OBP</th>\n",
       "      <th>away_AVG</th>\n",
       "      <th>away_singles</th>\n",
       "      <th>away_SLG</th>\n",
       "      <th>away_BABIP</th>\n",
       "      <th>away_ISO</th>\n",
       "      <th>away_PASO</th>\n",
       "      <th>away_total_bases</th>\n",
       "      <th>away_runs_created</th>\n",
       "      <th>away_wOBA</th>\n",
       "      <th>away_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>CHN</td>\n",
       "      <td>NYN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.309524</td>\n",
       "      <td>0.209512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.422222</td>\n",
       "      <td>0.288298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>SLN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.121951</td>\n",
       "      <td>0.450488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.309524</td>\n",
       "      <td>0.209512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>COL</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.354839</td>\n",
       "      <td>0.314375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.939394</td>\n",
       "      <td>0.241290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>CIN</td>\n",
       "      <td>MIL</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.336500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>0.372593</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-04-03</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SFN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.270270</td>\n",
       "      <td>0.348158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.805556</td>\n",
       "      <td>0.361667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48563</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>KCA</td>\n",
       "      <td>MIN</td>\n",
       "      <td>4.265432</td>\n",
       "      <td>33.913580</td>\n",
       "      <td>8.345679</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>0.253086</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>4.037037</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>2.814815</td>\n",
       "      <td>0.104938</td>\n",
       "      <td>8.672840</td>\n",
       "      <td>0.734568</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>6.518519</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>5.080247</td>\n",
       "      <td>5.080247</td>\n",
       "      <td>0.364198</td>\n",
       "      <td>26.388889</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302356</td>\n",
       "      <td>0.241805</td>\n",
       "      <td>5.376543</td>\n",
       "      <td>0.391838</td>\n",
       "      <td>0.295313</td>\n",
       "      <td>0.150032</td>\n",
       "      <td>4.453555</td>\n",
       "      <td>13.555556</td>\n",
       "      <td>4.394609</td>\n",
       "      <td>0.306786</td>\n",
       "      <td>0.364198</td>\n",
       "      <td>5.783951</td>\n",
       "      <td>35.358025</td>\n",
       "      <td>9.537037</td>\n",
       "      <td>1.969136</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>1.876543</td>\n",
       "      <td>5.580247</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.253086</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>3.246914</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.623457</td>\n",
       "      <td>6.901235</td>\n",
       "      <td>4.209877</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>27.111111</td>\n",
       "      <td>8.648148</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.263486</td>\n",
       "      <td>5.549383</td>\n",
       "      <td>0.482237</td>\n",
       "      <td>0.292265</td>\n",
       "      <td>0.218751</td>\n",
       "      <td>5.042836</td>\n",
       "      <td>17.419753</td>\n",
       "      <td>6.125828</td>\n",
       "      <td>0.355849</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48564</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>SEA</td>\n",
       "      <td>OAK</td>\n",
       "      <td>4.664596</td>\n",
       "      <td>34.043478</td>\n",
       "      <td>8.074534</td>\n",
       "      <td>1.583851</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1.478261</td>\n",
       "      <td>4.490683</td>\n",
       "      <td>0.080745</td>\n",
       "      <td>0.229814</td>\n",
       "      <td>0.360248</td>\n",
       "      <td>3.614907</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>9.770186</td>\n",
       "      <td>0.708075</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>6.683230</td>\n",
       "      <td>4.316770</td>\n",
       "      <td>4.937888</td>\n",
       "      <td>4.931677</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>26.708075</td>\n",
       "      <td>9.211180</td>\n",
       "      <td>0.819876</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304195</td>\n",
       "      <td>0.230834</td>\n",
       "      <td>4.838509</td>\n",
       "      <td>0.413656</td>\n",
       "      <td>0.278795</td>\n",
       "      <td>0.182822</td>\n",
       "      <td>3.808844</td>\n",
       "      <td>14.440994</td>\n",
       "      <td>4.817710</td>\n",
       "      <td>0.315829</td>\n",
       "      <td>0.416149</td>\n",
       "      <td>5.223602</td>\n",
       "      <td>34.422360</td>\n",
       "      <td>8.583851</td>\n",
       "      <td>1.795031</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.577640</td>\n",
       "      <td>4.937888</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.223602</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>3.583851</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>8.273292</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>6.726708</td>\n",
       "      <td>4.378882</td>\n",
       "      <td>3.968944</td>\n",
       "      <td>3.968944</td>\n",
       "      <td>0.440994</td>\n",
       "      <td>27.204969</td>\n",
       "      <td>9.080745</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.118012</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320712</td>\n",
       "      <td>0.243866</td>\n",
       "      <td>5.068323</td>\n",
       "      <td>0.438236</td>\n",
       "      <td>0.276044</td>\n",
       "      <td>0.194369</td>\n",
       "      <td>4.837578</td>\n",
       "      <td>15.397516</td>\n",
       "      <td>5.224355</td>\n",
       "      <td>0.334599</td>\n",
       "      <td>0.602484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48565</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>SLN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>4.685185</td>\n",
       "      <td>33.635802</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>1.518519</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.296296</td>\n",
       "      <td>4.382716</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>3.425926</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>8.790123</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>6.802469</td>\n",
       "      <td>4.351852</td>\n",
       "      <td>3.814815</td>\n",
       "      <td>3.790123</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>26.722222</td>\n",
       "      <td>9.753086</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.043210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314020</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>5.259259</td>\n",
       "      <td>0.405582</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>0.165882</td>\n",
       "      <td>4.531670</td>\n",
       "      <td>13.925926</td>\n",
       "      <td>4.668923</td>\n",
       "      <td>0.318989</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>5.098765</td>\n",
       "      <td>33.771605</td>\n",
       "      <td>8.567901</td>\n",
       "      <td>1.685185</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>1.598765</td>\n",
       "      <td>4.901235</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>3.629630</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>9.012346</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>6.648148</td>\n",
       "      <td>4.561728</td>\n",
       "      <td>4.024691</td>\n",
       "      <td>4.024691</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>26.722222</td>\n",
       "      <td>10.012346</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>0.248821</td>\n",
       "      <td>5.123457</td>\n",
       "      <td>0.445114</td>\n",
       "      <td>0.293358</td>\n",
       "      <td>0.196293</td>\n",
       "      <td>4.302921</td>\n",
       "      <td>15.370370</td>\n",
       "      <td>5.371081</td>\n",
       "      <td>0.339673</td>\n",
       "      <td>0.524691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48566</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>PHI</td>\n",
       "      <td>MIA</td>\n",
       "      <td>4.820988</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>8.413580</td>\n",
       "      <td>1.913580</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.623457</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>3.487654</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>8.962963</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>6.907407</td>\n",
       "      <td>4.462963</td>\n",
       "      <td>4.518519</td>\n",
       "      <td>4.512346</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>26.919753</td>\n",
       "      <td>9.623457</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311880</td>\n",
       "      <td>0.238968</td>\n",
       "      <td>5.006173</td>\n",
       "      <td>0.417831</td>\n",
       "      <td>0.283455</td>\n",
       "      <td>0.178863</td>\n",
       "      <td>4.302181</td>\n",
       "      <td>14.648148</td>\n",
       "      <td>4.925803</td>\n",
       "      <td>0.324113</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>3.790123</td>\n",
       "      <td>34.018519</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>1.629630</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>3.654321</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>9.055556</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>6.395062</td>\n",
       "      <td>4.320988</td>\n",
       "      <td>4.703704</td>\n",
       "      <td>4.703704</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>26.746914</td>\n",
       "      <td>8.425926</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290343</td>\n",
       "      <td>0.233562</td>\n",
       "      <td>5.524691</td>\n",
       "      <td>0.363893</td>\n",
       "      <td>0.289528</td>\n",
       "      <td>0.130330</td>\n",
       "      <td>4.255174</td>\n",
       "      <td>12.722222</td>\n",
       "      <td>4.038393</td>\n",
       "      <td>0.291321</td>\n",
       "      <td>0.345679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>TOR</td>\n",
       "      <td>TBA</td>\n",
       "      <td>4.432099</td>\n",
       "      <td>33.888889</td>\n",
       "      <td>7.962963</td>\n",
       "      <td>1.641975</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>1.512346</td>\n",
       "      <td>4.253086</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>3.129630</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>4.641975</td>\n",
       "      <td>4.728395</td>\n",
       "      <td>4.728395</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>26.691358</td>\n",
       "      <td>9.283951</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>0.227517</td>\n",
       "      <td>4.679012</td>\n",
       "      <td>0.412137</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>0.184620</td>\n",
       "      <td>4.182398</td>\n",
       "      <td>14.401235</td>\n",
       "      <td>4.765107</td>\n",
       "      <td>0.310220</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>4.734568</td>\n",
       "      <td>34.709877</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>1.783951</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>1.339506</td>\n",
       "      <td>4.493827</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>3.345679</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>9.228395</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.228395</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>6.969136</td>\n",
       "      <td>4.697531</td>\n",
       "      <td>3.697531</td>\n",
       "      <td>3.672840</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>27.320988</td>\n",
       "      <td>8.759259</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319969</td>\n",
       "      <td>0.249172</td>\n",
       "      <td>5.475309</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.301012</td>\n",
       "      <td>0.176490</td>\n",
       "      <td>4.381805</td>\n",
       "      <td>14.938272</td>\n",
       "      <td>5.045790</td>\n",
       "      <td>0.329316</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48568 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date home_team away_team  home_team_score  home_at_bats  \\\n",
       "0      2000-03-30       CHN       NYN         1.000000     36.000000   \n",
       "1      2000-04-03       SLN       CHN         7.000000     34.000000   \n",
       "2      2000-04-03       ATL       COL         2.000000     30.000000   \n",
       "3      2000-04-03       CIN       MIL         3.000000     19.000000   \n",
       "4      2000-04-03       MIA       SFN         6.000000     36.000000   \n",
       "...           ...       ...       ...              ...           ...   \n",
       "48563  2019-09-29       KCA       MIN         4.265432     33.913580   \n",
       "48564  2019-09-29       SEA       OAK         4.664596     34.043478   \n",
       "48565  2019-09-29       SLN       CHN         4.685185     33.635802   \n",
       "48566  2019-09-29       PHI       MIA         4.820988     34.333333   \n",
       "48567  2019-09-29       TOR       TBA         4.432099     33.888889   \n",
       "\n",
       "       home_hits  home_doubles  home_triples  home_hrs  home_rbi   home_sh  \\\n",
       "0       5.000000      0.000000      0.000000  0.000000  0.000000  2.000000   \n",
       "1      10.000000      1.000000      1.000000  3.000000  7.000000  0.000000   \n",
       "2       7.000000      0.000000      0.000000  2.000000  2.000000  0.000000   \n",
       "3       5.000000      1.000000      0.000000  1.000000  3.000000  0.000000   \n",
       "4      12.000000      3.000000      0.000000  0.000000  5.000000  0.000000   \n",
       "...          ...           ...           ...       ...       ...       ...   \n",
       "48563   8.345679      1.722222      0.253086  0.993827  4.037037  0.148148   \n",
       "48564   8.074534      1.583851      0.173913  1.478261  4.490683  0.080745   \n",
       "48565   8.222222      1.518519      0.148148  1.296296  4.382716  0.246914   \n",
       "48566   8.413580      1.913580      0.160494  1.333333  4.623457  0.209877   \n",
       "48567   7.962963      1.641975      0.129630  1.512346  4.253086  0.086420   \n",
       "\n",
       "        home_sf  home_hbp  home_walk  home_int_walk   home_so   home_sb  \\\n",
       "0      0.000000  0.000000   6.000000       1.000000  9.000000  0.000000   \n",
       "1      0.000000  0.000000   7.000000       0.000000  6.000000  3.000000   \n",
       "2      0.000000  1.000000   1.000000       0.000000  6.000000  1.000000   \n",
       "3      0.000000  0.000000   1.000000       0.000000  4.000000  0.000000   \n",
       "4      0.000000  1.000000   1.000000       0.000000  7.000000  1.000000   \n",
       "...         ...       ...        ...            ...       ...       ...   \n",
       "48563  0.259259  0.370370   2.814815       0.104938  8.672840  0.734568   \n",
       "48564  0.229814  0.360248   3.614907       0.043478  9.770186  0.708075   \n",
       "48565  0.240741  0.462963   3.425926       0.092593  8.790123  0.709877   \n",
       "48566  0.209877  0.351852   3.487654       0.302469  8.962963  0.481481   \n",
       "48567  0.172840  0.271605   3.129630       0.061728  9.333333  0.302469   \n",
       "\n",
       "        home_cs  home_gidp  home_left_on_base  home_pitchers_used  \\\n",
       "0      0.000000   2.000000          10.000000            7.000000   \n",
       "1      0.000000   0.000000          10.000000            4.000000   \n",
       "2      0.000000   1.000000           6.000000            2.000000   \n",
       "3      0.000000   0.000000           2.000000            2.000000   \n",
       "4      0.000000   1.000000           8.000000            3.000000   \n",
       "...         ...        ...                ...                 ...   \n",
       "48563  0.240741   0.697531           6.518519            4.222222   \n",
       "48564  0.285714   0.521739           6.683230            4.316770   \n",
       "48565  0.179012   0.672840           6.802469            4.351852   \n",
       "48566  0.111111   0.592593           6.907407            4.462963   \n",
       "48567  0.123457   0.660494           6.166667            4.641975   \n",
       "\n",
       "       home_pitch_earned_runs  home_team_earned_runs  home_pitch_wild_pitches  \\\n",
       "0                    5.000000               5.000000                 0.000000   \n",
       "1                    1.000000               1.000000                 0.000000   \n",
       "2                    0.000000               0.000000                 0.000000   \n",
       "3                    2.000000               2.000000                 0.000000   \n",
       "4                    4.000000               4.000000                 0.000000   \n",
       "...                       ...                    ...                      ...   \n",
       "48563                5.080247               5.080247                 0.364198   \n",
       "48564                4.937888               4.931677                 0.447205   \n",
       "48565                3.814815               3.790123                 0.283951   \n",
       "48566                4.518519               4.512346                 0.271605   \n",
       "48567                4.728395               4.728395                 0.432099   \n",
       "\n",
       "       home_def_putouts  home_def_assists  home_def_errors  \\\n",
       "0             33.000000         14.000000         0.000000   \n",
       "1             27.000000          8.000000         0.000000   \n",
       "2             27.000000         12.000000         0.000000   \n",
       "3             16.000000          8.000000         2.000000   \n",
       "4             27.000000         15.000000         0.000000   \n",
       "...                 ...               ...              ...   \n",
       "48563         26.388889          9.333333         0.444444   \n",
       "48564         26.708075          9.211180         0.819876   \n",
       "48565         26.722222          9.753086         0.407407   \n",
       "48566         26.919753          9.623457         0.592593   \n",
       "48567         26.691358          9.283951         0.586420   \n",
       "\n",
       "       home_def_passed_balls  home_def_double_plays  home_def_triple_plays  \\\n",
       "0                   0.000000               0.000000                    0.0   \n",
       "1                   0.000000               1.000000                    0.0   \n",
       "2                   0.000000               1.000000                    0.0   \n",
       "3                   0.000000               0.000000                    0.0   \n",
       "4                   0.000000               2.000000                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "48563               0.061728               0.932099                    0.0   \n",
       "48564               0.037267               0.900621                    0.0   \n",
       "48565               0.037037               1.043210                    0.0   \n",
       "48566               0.067901               0.864198                    0.0   \n",
       "48567               0.055556               0.870370                    0.0   \n",
       "\n",
       "       home_OBP  home_AVG  home_singles  home_SLG  home_BABIP  home_ISO  \\\n",
       "0      0.261905  0.138889      5.000000  0.138889    0.185185  0.000000   \n",
       "1      0.414634  0.294118      5.000000  0.647059    0.280000  0.352941   \n",
       "2      0.281250  0.233333      5.000000  0.433333    0.227273  0.200000   \n",
       "3      0.300000  0.263158      3.000000  0.473684    0.285714  0.210526   \n",
       "4      0.368421  0.333333      9.000000  0.416667    0.413793  0.083333   \n",
       "...         ...       ...           ...       ...         ...       ...   \n",
       "48563  0.302356  0.241805      5.376543  0.391838    0.295313  0.150032   \n",
       "48564  0.304195  0.230834      4.838509  0.413656    0.278795  0.182822   \n",
       "48565  0.314020  0.239700      5.259259  0.405582    0.285247  0.165882   \n",
       "48566  0.311880  0.238968      5.006173  0.417831    0.283455  0.178863   \n",
       "48567  0.293909  0.227517      4.679012  0.412137    0.268487  0.184620   \n",
       "\n",
       "       home_PASO  home_total_bases  home_runs_created  home_wOBA  \\\n",
       "0       4.000000          5.000000           1.309524   0.209512   \n",
       "1       5.666667         22.000000           9.121951   0.450488   \n",
       "2       5.000000         13.000000           3.354839   0.314375   \n",
       "3       4.750000          9.000000           2.700000   0.336500   \n",
       "4       5.142857         15.000000           5.270270   0.348158   \n",
       "...          ...               ...                ...        ...   \n",
       "48563   4.453555         13.555556           4.394609   0.306786   \n",
       "48564   3.808844         14.440994           4.817710   0.315829   \n",
       "48565   4.531670         13.925926           4.668923   0.318989   \n",
       "48566   4.302181         14.648148           4.925803   0.324113   \n",
       "48567   4.182398         14.401235           4.765107   0.310220   \n",
       "\n",
       "       home_outcome  away_team_score  away_at_bats  away_hits  away_doubles  \\\n",
       "0          0.000000         5.000000     37.000000   6.000000      2.000000   \n",
       "1          1.000000         1.000000     36.000000   5.000000      0.000000   \n",
       "2          1.000000         0.000000     31.000000   6.000000      2.000000   \n",
       "3         -1.000000         3.000000     22.000000   7.000000      1.000000   \n",
       "4          1.000000         4.000000     35.000000  10.000000      2.000000   \n",
       "...             ...              ...           ...        ...           ...   \n",
       "48563      0.364198         5.783951     35.358025   9.537037      1.969136   \n",
       "48564      0.416149         5.223602     34.422360   8.583851      1.795031   \n",
       "48565      0.555556         5.098765     33.771605   8.567901      1.685185   \n",
       "48566      0.506173         3.790123     34.018519   8.166667      1.629630   \n",
       "48567      0.407407         4.734568     34.709877   8.777778      1.783951   \n",
       "\n",
       "       away_triples  away_hrs  away_rbi   away_sh   away_sf  away_hbp  \\\n",
       "0          0.000000  1.000000  5.000000  1.000000  1.000000  1.000000   \n",
       "1          0.000000  0.000000  0.000000  2.000000  0.000000  0.000000   \n",
       "2          0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "3          0.000000  0.000000  2.000000  0.000000  0.000000  0.000000   \n",
       "4          2.000000  1.000000  4.000000  0.000000  0.000000  0.000000   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "48563      0.141975  1.876543  5.580247  0.061728  0.253086  0.506173   \n",
       "48564      0.142857  1.577640  4.937888  0.043478  0.223602  0.540373   \n",
       "48565      0.160494  1.598765  4.901235  0.185185  0.240741  0.518519   \n",
       "48566      0.111111  0.901235  3.654321  0.191358  0.203704  0.456790   \n",
       "48567      0.179012  1.339506  4.493827  0.049383  0.209877  0.462963   \n",
       "\n",
       "       away_walk  away_int_walk   away_so   away_sb   away_cs  away_gidp  \\\n",
       "0       8.000000       0.000000  5.000000  1.000000  0.000000   0.000000   \n",
       "1       6.000000       1.000000  9.000000  0.000000  0.000000   2.000000   \n",
       "2       2.000000       2.000000  7.000000  0.000000  0.000000   1.000000   \n",
       "3       5.000000       0.000000  1.000000  1.000000  0.000000   0.000000   \n",
       "4       1.000000       0.000000  8.000000  0.000000  0.000000   2.000000   \n",
       "...          ...            ...       ...       ...       ...        ...   \n",
       "48563   3.246914       0.129630  8.222222  0.172840  0.129630   0.623457   \n",
       "48564   3.583851       0.105590  8.273292  0.298137  0.130435   0.863354   \n",
       "48565   3.629630       0.203704  9.012346  0.277778  0.154321   0.783951   \n",
       "48566   2.444444       0.098765  9.055556  0.339506  0.172840   0.858025   \n",
       "48567   3.345679       0.123457  9.228395  0.574074  0.228395   0.703704   \n",
       "\n",
       "       away_left_on_base  away_pitchers_used  away_pitch_earned_runs  \\\n",
       "0              10.000000            5.000000                0.000000   \n",
       "1              10.000000            7.000000                5.000000   \n",
       "2               7.000000            3.000000                2.000000   \n",
       "3               8.000000            1.000000                3.000000   \n",
       "4               5.000000            2.000000                4.000000   \n",
       "...                  ...                 ...                     ...   \n",
       "48563           6.901235            4.209877                4.166667   \n",
       "48564           6.726708            4.378882                3.968944   \n",
       "48565           6.648148            4.561728                4.024691   \n",
       "48566           6.395062            4.320988                4.703704   \n",
       "48567           6.969136            4.697531                3.697531   \n",
       "\n",
       "       away_team_earned_runs  away_pitch_wild_pitches  away_def_putouts  \\\n",
       "0                   0.000000                 0.000000         33.000000   \n",
       "1                   5.000000                 0.000000         33.000000   \n",
       "2                   2.000000                 1.000000         24.000000   \n",
       "3                   3.000000                 0.000000         15.000000   \n",
       "4                   4.000000                 0.000000         24.000000   \n",
       "...                      ...                      ...               ...   \n",
       "48563               4.166667                 0.438272         27.111111   \n",
       "48564               3.968944                 0.440994         27.204969   \n",
       "48565               4.024691                 0.370370         26.722222   \n",
       "48566               4.703704                 0.438272         26.746914   \n",
       "48567               3.672840                 0.358025         27.320988   \n",
       "\n",
       "       away_def_assists  away_def_errors  away_def_passed_balls  \\\n",
       "0             14.000000         2.000000               0.000000   \n",
       "1             14.000000         0.000000               0.000000   \n",
       "2             10.000000         0.000000               0.000000   \n",
       "3              5.000000         0.000000               0.000000   \n",
       "4              7.000000         2.000000               0.000000   \n",
       "...                 ...              ...                    ...   \n",
       "48563          8.648148         0.679012               0.092593   \n",
       "48564          9.080745         0.496894               0.118012   \n",
       "48565         10.012346         0.728395               0.061728   \n",
       "48566          8.425926         0.586420               0.080247   \n",
       "48567          8.759259         0.537037               0.098765   \n",
       "\n",
       "       away_def_double_plays  away_def_triple_plays  away_OBP  away_AVG  \\\n",
       "0                   2.000000               0.000000  0.319149  0.162162   \n",
       "1                   0.000000               0.000000  0.261905  0.138889   \n",
       "2                   1.000000               0.000000  0.242424  0.193548   \n",
       "3                   0.000000               0.000000  0.444444  0.318182   \n",
       "4                   1.000000               0.000000  0.305556  0.285714   \n",
       "...                      ...                    ...       ...       ...   \n",
       "48563               0.796296               0.012346  0.331831  0.263486   \n",
       "48564               0.770186               0.000000  0.320712  0.243866   \n",
       "48565               0.870370               0.000000  0.325811  0.248821   \n",
       "48566               0.833333               0.000000  0.290343  0.233562   \n",
       "48567               0.796296               0.000000  0.319969  0.249172   \n",
       "\n",
       "       away_singles  away_SLG  away_BABIP  away_ISO  away_PASO  \\\n",
       "0          3.000000  0.297297    0.156250  0.135135   7.400000   \n",
       "1          5.000000  0.138889    0.185185  0.000000   4.000000   \n",
       "2          4.000000  0.258065    0.250000  0.064516   4.428571   \n",
       "3          6.000000  0.363636    0.333333  0.045455  22.000000   \n",
       "4          5.000000  0.542857    0.346154  0.257143   4.375000   \n",
       "...             ...       ...         ...       ...        ...   \n",
       "48563      5.549383  0.482237    0.292265  0.218751   5.042836   \n",
       "48564      5.068323  0.438236    0.276044  0.194369   4.837578   \n",
       "48565      5.123457  0.445114    0.293358  0.196293   4.302921   \n",
       "48566      5.524691  0.363893    0.289528  0.130330   4.255174   \n",
       "48567      5.475309  0.425662    0.301012  0.176490   4.381805   \n",
       "\n",
       "       away_total_bases  away_runs_created  away_wOBA  away_outcome  \n",
       "0             11.000000           3.422222   0.288298      1.000000  \n",
       "1              5.000000           1.309524   0.209512      0.000000  \n",
       "2              8.000000           1.939394   0.241290      0.000000  \n",
       "3              8.000000           3.555556   0.372593     -1.000000  \n",
       "4             19.000000           5.805556   0.361667      0.000000  \n",
       "...                 ...                ...        ...           ...  \n",
       "48563         17.419753           6.125828   0.355849      0.629630  \n",
       "48564         15.397516           5.224355   0.334599      0.602484  \n",
       "48565         15.370370           5.371081   0.339673      0.524691  \n",
       "48566         12.722222           4.038393   0.291321      0.345679  \n",
       "48567         14.938272           5.045790   0.329316      0.592593  \n",
       "\n",
       "[48568 rows x 79 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching Target to aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_for_attaching_to_agg = df_norm[['Date','home_team','away_team','home_outcome','away_outcome','game_number_of_season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_for_attaching_to_agg.rename(columns={'home_outcome':'home_outcome_nonagg','away_outcome':'away_outcome_nonagg'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg.merge(info_for_attaching_to_agg,how='left',on=['Date','home_team','away_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_cutt_early = df_agg[(df_agg.game_number_of_season > 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data (stats are averaged as season goes on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping cols for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_agg = ['home_team','away_team','Date','away_outcome_nonagg','game_number_of_season']\n",
    "df_agg.drop(columns=cols_to_drop_agg,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going to use cutt data as the first 10 games cant be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_agg_cutt = ['home_team','away_team','Date','away_outcome_nonagg','game_number_of_season']\n",
    "df_agg_cutt_early.drop(columns=cols_to_drop_agg_cutt,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_cutt_early.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_agg_cutt_early.dropna(inplace=True)\n",
    "df_agg_cutt_early.replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "df_agg_cutt_early.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target in this case is the home_outcome_nonagg (non aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg_cutt = df_agg_cutt_early.drop(columns='home_outcome_nonagg')\n",
    "y_agg_cutt = df_agg_cutt_early.home_outcome_nonagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5643580939619798\n",
      "Logistic Regression Test Accuracy: 0.5691496043210652\n",
      "Tree Accuracy: 0.7988443178963236\n",
      "Tree Test Accuracy: 0.5395050873005903\n",
      "Random Forest Accuracy: 0.9911230215224855\n",
      "Random Forest Test Accuracy: 0.5274463007159904\n",
      "XGBoost Accuracy: 0.6079055355497864\n",
      "XGBoost Test Accuracy: 0.5694008290415777\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg_cutt,y_agg_cutt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Feature Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5643580939619798\n",
      "Logistic Regression Test Accuracy: 0.5691496043210652\n"
     ]
    }
   ],
   "source": [
    "X_train_agg_cutt, X_test_agg_cutt, y_train_agg_cutt, y_test_agg_cutt = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_final = LogisticRegression(random_state=99)\n",
    "lr_final.fit(X_train_agg_cutt,y_train_agg_cutt)\n",
    "pred_lr_final = lr_final.predict(X_train_agg_cutt)\n",
    "score_lr_final = accuracy_score(y_train_agg_cutt,pred_lr_final)\n",
    "print('Logistic Regression Accuracy: {}'.format(score_lr_final))\n",
    "\n",
    "pred_lr_final_test = lr_final.predict(X_test_agg_cutt)\n",
    "score_lr_final_test = accuracy_score(y_test_agg_cutt,pred_lr_final_test)\n",
    "print('Logistic Regression Test Accuracy: {}'.format(score_lr_final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lr_final.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_agg_cutt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_list = []\n",
    "for feature, importance in zip(features,feature_importance):\n",
    "    feature_importance_list.append((feature,importance))\n",
    "feature_importance_list.sort(key=lambda x: np.abs(x[1]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('away_at_bats', -0.04405134849609969),\n",
       " ('home_at_bats', -0.04234475888819748),\n",
       " ('away_def_putouts', -0.03440176071711852),\n",
       " ('home_def_putouts', -0.02998623588342763),\n",
       " ('home_total_bases', -0.018536903156170906),\n",
       " ('away_pitch_earned_runs', -0.012799224019945566),\n",
       " ('away_team_earned_runs', -0.012766346795195452),\n",
       " ('away_so', -0.012537329129827364),\n",
       " ('away_def_assists', -0.011454611826550939),\n",
       " ('home_pitch_earned_runs', -0.011114388804262427)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25937979199415206"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.home_AVG.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data cutting first 10 games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_cutt,y_agg_cutt,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=10,n_jobs=-1,min_features_to_select=15)\n",
    "\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature pre feature selection: 76\n",
      "# of feature post feature selection: 50\n"
     ]
    }
   ],
   "source": [
    "print('# of feature pre feature selection: {}'.format(len(X_train.columns)))\n",
    "print('# of feature post feature selection: {}'.format(len(selected_wrapper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5635625157022025\n",
      "Logistic Regression Test Accuracy: 0.5678934807185027\n",
      "Tree Accuracy: 0.7780755380621388\n",
      "Tree Test Accuracy: 0.5315915086044467\n",
      "Random Forest Accuracy: 0.9911230215224855\n",
      "Random Forest Test Accuracy: 0.5229242557467655\n",
      "XGBoost Accuracy: 0.6047650950506658\n",
      "XGBoost Test Accuracy: 0.5657580705941465\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction(X_agg[selected_wrapper],y_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection using the wrapper method actually saw a loss in performance in almost every metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   48.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5605054012913738\n",
      "{'C': 0.05, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.05, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = { \n",
    "    'penalty': ['l2','l1','elasticnet'],\n",
    "    'C': [0.1,0.05,0.01],\n",
    "    'max_iter':[1000],\n",
    "    \n",
    "}\n",
    "\n",
    "grid_lr=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid_lr, \n",
    "                         cv=10, \n",
    "                         scoring='accuracy', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train,y_train)\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_lr.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.565866\n",
      "Test Accuracy: 0.566763\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_test = grid_lr.best_estimator_.predict(X_test)\n",
    "\n",
    "y_pred_train = grid_lr.best_estimator_.predict(X_train)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Train Accuracy: %f\" % (train_acc))\n",
    "print(\"Test Accuracy: %f\" % (test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6079055355497864\n",
      "XGBoost Test Accuracy: 0.5694008290415777\n"
     ]
    }
   ],
   "source": [
    "#XG Boost\n",
    "xg_cutt = xgb.XGBClassifier(objecteve='binary:logistic')\n",
    "xg_cutt.fit(X_train_agg_cutt,y_train_agg_cutt)\n",
    "pred_xg_cutt = xg_cutt.predict(X_train_agg_cutt)\n",
    "score_xg_cutt = accuracy_score(y_train_agg_cutt,pred_xg_cutt)\n",
    "print('XGBoost Accuracy: {}'.format(score_xg_cutt))\n",
    "\n",
    "pred_xg_cutt_test = xg_cutt.predict(X_test_agg_cutt)\n",
    "score_xg_cutt_test = accuracy_score(y_test_agg_cutt,pred_xg_cutt_test)\n",
    "print('XGBoost Test Accuracy: {}'.format(score_xg_cutt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAEWCAYAAACg1nQiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeZgU1fm27wdEBVEIcYmggqiIsiogGlGHGDQmoGKIxOACxnwhUcFdEzckJqBo0GCM209xXxAVNHGXEaO4gA6gJuM6CUQSFgVEAVne749zGoqme6YHmOkaeO/rqqurTp2q81SL8/ZZ6n1kZjiO4ziOUzeoV2wBjuM4juMUjgdux3Ecx6lDeOB2HMdxnDqEB27HcRzHqUN44HYcx3GcOoQHbsdxHMepQ3jgdhxns0XSLZIuL7YOx9mUyN/jdhwnG0kVwC7AqkRxGzP7bCPuWQLcZ2a7bZy6uomkscBsM7us2Fqcuo33uB3HyUcfM2uc2DY4aG8KJG1VzPY3Bkn1i63B2XzwwO04TrWQdLCk1yQtlDQ99qQz5wZJ+oekLyV9IumXsXw74GmguaQlcWsuaaykqxPXl0ianTiukHSxpBnAV5K2iteNlzRP0qeShlSidc39M/eWdJGkuZLmSDpe0g8lfSDpc0m/TVw7TNKjkh6Oz/O2pE6J8/tJKo3fw3uSjs1q9y+S/ibpK+DnwADgovjsT8Z6l0j6ON7/fUl9E/cYKOnvkq6T9EV81mMS55tJukvSZ/H8E4lzvSWVRW2vSepY8H9gJ/V44HYcp2AktQD+ClwNNAMuAMZL2ilWmQv0BnYABgGjJR1oZl8BxwCfbUAP/iTgR0BTYDXwJDAdaAEcCZwj6egC7/UdYNt47RXA7cDJQBfgMOAKSa0T9Y8DxsVnfQB4QlIDSQ2ijueAnYGzgfsl7Zu49mfA74HtgXuA+4Fr47P3iXU+ju02Aa4C7pO0a+Ie3YFyYEfgWuD/JCmeuxdoBLSLGkYDSDoQuBP4JfBt4FZgoqRtCvyOnJTjgdtxnHw8EXtsCxO9uZOBv5nZ38xstZk9D0wFfghgZn81s48t8DIhsB22kTr+ZGazzGwp0A3YycyGm9k3ZvYJIfj+tMB7rQB+b2YrgIcIAfFGM/vSzN4D3gOSvdNpZvZorP9HQtA/OG6NgZFRx0vAU4QfGRkmmNmr8XtalkuMmY0zs89inYeBD4GDElX+ZWa3m9kq4G5gV2CXGNyPAQab2RdmtiJ+3wC/AG41szfMbJWZ3Q0sj5qdzYA6O2fkOE6Nc7yZvZBV1hL4iaQ+ibIGwCSAOJR7JdCG0DFoBMzcSB2zstpvLmlhoqw+8EqB91oQgyDA0vj5v8T5pYSAvF7bZrY6DuM3z5wzs9WJuv8i9ORz6c6JpFOB84BWsagx4cdEhv8m2v86drYbE0YAPjezL3LctiVwmqSzE2VbJ3Q7dRwP3I7jVIdZwL1m9ovsE3EodjxwKqG3uSL21DNDu7leYfmKENwzfCdHneR1s4BPzWyfDRG/Aeye2ZFUD9gNyAzx7y6pXiJ47wF8kLg2+3nXOZbUkjBacCQwxcxWSSpj7fdVGbOAZpKamtnCHOd+b2a/L+A+Th3Eh8odx6kO9wF9JB0tqb6kbeOir90IvbptgHnAytj7Pipx7f+Ab0tqkigrA34YF1p9BzinivbfBBbHBWsNo4b2krptsidcly6STogr2s8hDDm/DrxB+NFxUZzzLgH6EIbf8/E/IDl/vh0hmM+DsLAPaF+IKDObQ1jsd7Okb0UNh8fTtwODJXVXYDtJP5K0fYHP7KQcD9yO4xSMmc0iLNj6LSHgzAIuBOqZ2ZfAEOAR4AvC4qyJiWv/CTwIfBLnzZsTFlhNByoI8+EPV9H+KkKA7Ax8CswH7iAs7qoJJgD9Cc9zCnBCnE/+BjiWMM88H7gZODU+Yz7+D9g/s2bAzN4HrgemEIJ6B+DVamg7hTBn/0/CosBzAMxsKmGe+6ao+yNgYDXu66QcT8DiOI6TA0nDgL3N7ORia3GcJN7jdhzHcZw6hAdux3Ecx6lD+FC54ziO49QhvMftOI7jOHUIf4/bqXGaNm1qe++9d7FlrMdXX33FdtttV2wZOUmrtrTqgvRqS6suSK+2tOqC2tU2bdq0+Wa2U3a5B26nxtlll12YOnVqsWWsR2lpKSUlJcWWkZO0akurLkivtrTqgvRqS6suqF1tkv6Vq9yHyh3HcRynDuGB23Ecx3HqEB64HcdxHKcO4YHbcRzHceoQHrgdx3Ecpw7hgdtxHMdx6hAeuB3HcRynDuGB23Ecx3HqEB64HcdxHKcalJeX07lz5zXbDjvswA033MD06dM55JBD6NChA3369GHx4sU10r4HbsdxHMepBvvuuy9lZWWUlZUxbdo0GjVqRN++fTnjjDMYOXIkM2fOpG/fvowaNapG2vfAXQeQdIek/auoc3xVdTai/YGSbor7YyX1q4l2HMdx6hovvvgie+21Fy1btqS8vJzDDz8cgF69ejF+/PgaadNzldcBzOyMAqodDzwFvF/DcqrN0hWraHXJX4stYz3O77CSgSnUBenVllZdkF5tadUF6dWWJl0VI39U6fmHHnqIk046CYD27dszceJEjjvuOMaNG8esWbNqRJP7cVcDSU8AuwPbAjcCC4GDzew8SUOBoWbWWtJewN1m1kPSFUAfoCHwGvBLoDUwzswOjPfdB3jIzLrkabcUuMDMpkpaEtvuDSwFjgP2IgTtRXH7sZl9nHWPnYGnzayLpE5AGdDSzP4t6WOgA3AkcBmwNbAAGGBm/5M0EOhqZmdJGgs8ZWaPSvpd/D5ON7PVWe39P+D/Aey4405drrjh9mp+2zXPLg3hf0uLrSI3adWWVl2QXm1p1QXp1ZYmXR1aNFnneMmSJTRu3BiAFStW0K9fP+666y6aNWvGv//9b8aMGcOiRYs49NBDeeyxx5gwYcIGt92zZ89pZtZ1vRNm5luBG9AsfjYE3gVaAG/FskeBt2LZacCI5DVx/16gT9yfBHSO+38Azq6k3VJC4ASwxD2uBS6L+2OBflXofw/YATgrah0AtASmxPPfYu2PuTOA6+P+QOCmZDux7Vsz9Svb2rRpY2lk0qRJxZaQl7RqS6sus/RqS6sus/RqS6sus3W1PfHEE9arV6+c9crLy61bt24b1RYw1XL8TfU57uoxRNJ04HVCT3N3oLGk7eP+A8DhwGHAK/GanpLekDQT+B7QLpbfAQySVB/oH68thG8IvWuAaUCrauh/DTg0avxDDq27Ac9GrRcmtGZzOdDUzH4Z/3E5juNscTz44INrhskB5s6dC8Dq1au5+uqrGTx4cI2064G7QCSVAN8HDjGzTsA7hCHzKcAgoJwQAA8DDgFelbQtcDOhJ9wBuD1eAzAeOIYw5D3NzBYUKGVFIliuonrrFDL6WgITgE5AD2ByPD+G0LPuQBjS3zbXTQi99S6SmlWjbcdxnM2Gr7/+mueff54TTjhhTdmDDz5ImzZtaNu2Lc2bN2fQoEE10rYH7sJpAnxhZl9LagscHMsnAxfEz3eAnsByM1vE2sA3X1JjwhAzAGa2DHgW+Atw1ybQ9yWwfRV1JgMnAx9amJP+HPgh8Go83wT4T9w/rZL7PAOMBP4aRxscx3G2KBo1asSCBQto0mTtHPjQoUP54IMP+OCDDxg5ciSSaqRtD9yF8wywlaQZwO8Iw+UQerG7A5PNbBUwC/g7gJktJPSyZwJPEHqqSe4nzFk/twn0PQRcKOmduDhuPcysIu5meth/Bxaa2RfxeBgwTtIrwPzKGjOzcYRnmyip4UZqdxzHcQrEXwcrEDNbThjazoUS9Y7Kuu4ywkrtXPQA7owBv7K2SxL7jRP7jxIWxWFmrwJVvsdtZnsk9v9AmOvOHE8gDKFnXzOWsCgNMxuYKL8TuLOqNh3HcZxNhwfuIiHpccJrXN8rthbHcRyn7uCBu0iYWd/sshjM98wqvtjMnq3OvSX9mbB6PMmNZrYp5tIdx3GcIuJz3CnCzPqaWeesrVpBO97nzBz38aDtOE6Ns3DhQvr160fbtm3Zb7/9mDJlyppz1113HZKYP7/SJTROFXiPezMivrL2jZm9VmwtjuNsmQwdOpQf/OAHPProo3zzzTd8/fXXAMyaNYvnn3+ePfbYo4o7OFXhPe7NixLgu8UW4TjOlsnixYuZPHkyP//5zwHYeuutadq0KQDnnnsu1157bY29IrUl4T3uAihijvIjgesI/53eAn5lZsslVRBSoM6X1DXWGQgMBlZJOhk4G/gAuCW2S7z+NUnnAafHsjvM7AZJrQivvP2d8I76dML75VcBOxPylr8paTtCopYOUdewuBo9L24yUn3Sqi2tuiC92tKqCzZOWy7zjU8++YSddtqJQYMGMX36dLp06cKNN97Iiy++SIsWLejUqdPGSnbwHnehnB6Da1dgCCFhyWHx3GHAAkktCK93ZdKH3mRm3cysPSF497Zg/LFIUudYZxDxNatsYta1sUD/mMlsK+BX+QTGd7RvAUbHOe1XgD8BL8dMbwcC70nqEtvtTgjQv5B0QLzN3oQfJh2BtsDP4jNdAPw21rkUeMnMuhGSzYyKwdxxnC2clStX8vbbb/OrX/2Kd955h+22245hw4bx+9//nuHDhxdb3maD97gLY4ikzCrwqnKUPxbr9ZR0EdAIaEYw+HiStTnKzyPkKD8oT5v7Ap+a2Qfx+G7gTOCGauj+HnAqQHxXfJGkHsDjZvYVgKTHou6Jsb2Zsfw94EUzs5i7vFW851HAsZIuiMfbAnsA/0g2nOUOxhUdVlZDdu2wS8PQ40gjadWWVl2QXm1p1QUbp620tHS9ss8//5wdd9yRpUuXUlpayl577cXYsWP59NNP2XfffQGYN28e7dq14y9/+QvNmuXOmrxkyZKc908DadDmgbsKsnKUfx0tNnPlKD+dkKP8/ESO8q5mNkvSMNbNUX4l8BKV5yivbCJoJWtHS/LlE8/7SJWcW57YX504Xs3afysi2IaWV9aImd0G3Aaw77772tkDjqumzJqntLSUE0tKii0jJ2nVllZdkF5tadUFNaNt9OjR7Lrrruy7776UlpZy5JFHMmrUqDXnW7VqxdSpU9lxxx0r1VWS4u+s2Np8qLxqipWj/J9AK0l7x+NTgJfjfgWQmRf/ceKa7HzlLxKH1yXVl7RD1Hu8pEZxiLsva4f3C+FZ4GzFFSaJYXbHcRzGjBnDgAED6NixI2VlZfz2t7+t+iKnWniPu2qeAQbHHOXl5MlRLmkWIdhiZgslZXKUV5A7R/kJVJKj3MyWSRpEyB2eWZx2Szx9FfB/kn4LvJG47EngUUnHERanDQVuk/RzgpPYr8xsiqSxwJvxmjvM7J24OK0QfkcYrp8Rg3cFweHMcRyHzp07M3Xq1LznKyoqak/MZooH7iooco7yF4H1erRx4VmbHOUfEBaWJVlvjNrM/gj8MausAmifOB6Y65yZLSWskHccx3GKgAfuWsZzlDuO4zgbgwfuWqYmc5Q7juM4mz8euFNArmDuOI7jOLnwVeWO4ziOU4fwwO04juMUTC73rwsvvJC2bdvSsWNH+vbty8KFC4stc7PGA7fjOI5TMBn3r3/+859Mnz6d/fbbj169evHuu+8yY8YM2rRpw4gRI4otc7PGA/cWjKQKSeulL5I0LJHS1HEcB8jv/nXUUUex1VZhydTBBx/M7Nmziylzs8cXpzk1jruDVZ+0akurLkivtrTqgqq1ZTuA5XP/2m67tT5Dd955J/37968xzQ7IzIqtYYuniLahFQTzkj5AA+AnZvbPmFt9L6BF1HWtmd0e87YPBxYQTFAmA782s9U57p00GelyxQ23b+S3tOnZpSH8b2mxVeQmrdrSqgvSqy2tuqBqbR1aNFnnuLy8nF//+teMGTOG/fffnzFjxrDddttx+unBJfi+++6jvLyc4cOHb5Tv9pIlS2jcuPEGX1+T1Ka2nj17TjOzruudMDPfirwBzeJnQ+BdQsB8K5Y9Skh32gI4DRiRvCbu3wv0ifuTgM5x/w/A2ZW0W5E5D/yakP4UYBjBj7shsCMwC2gOlADLCD8Q6gPPA/2qer42bdpYGpk0aVKxJeQlrdrSqsssvdrSqsus+trmzJljLVu2XHM8efJk++EPf2hmZmPHjrWDDz7Yvvrqq1rXVZvUpjZgquX4m+pz3OlgiKTphDzoVdmGZgxBekp6I1pufg9oF8sztqH1CbahD1TRdsaGdBprrTsBJpjZUjObT/gxkLEffdPMPrGQrvVBQvpWx3G2AL7zne+w++67U14ezAFffPFF9t9/f5555hmuueYaJk6cSKNGjYqscvPH57iLTBFtQzNkrDtXse6/h+w5FKui3HGcLYCM+9c333xD69atueuuu+jWrRvLly+nV69eQFigdsstt1RxJ2dD8cBdfCqzDR0et4xt6FIzWySpaayTtA19FNa4imVsQ3++EbqOkzQC2I4wRH4JwdjkIEl7Av8i9Ohv24g2HMepY+Ry//roo4+KpGbLxIfKi88zwFbRNvR35LENJcwz/x2CbSiQsQ19gty2oUYltqEF8Cbw16jnd2b2WSyfAowkzMV/Cjy+EW04juM41cR73EXGimsb2iqxP5XQs8bMhlVy2ddm5u96OI7jFAkP3JsZbhvqOI6zeeOBezPDatA21MxKgdINFuc4juNsNB64twByBXPHcRynbuKL0xzHcWqJVatWccABB9C7d28Apk+fziGHHEKHDh3o06cPixcvLrJCpy7ggTsPklpJerfYOqqDpOMl7V9sHY7j5ObGG29kv/32W3N8xhlnMHLkSGbOnEnfvn0ZNWpUEdU5dQUfKt+8OB54Cni/2EKSuMlI9UmrtrTqgvRoyzbmyDB79mz++te/cumll/LHP/4RCLm/Dz/8cAB69erF0Ucfze9+97ta0+rUTbzHXTn1Jd0u6T1Jz0lqKKmzpNclzZD0uKRvAUgqlTRa0mRJ/5DUTdJjkj6UdHXmhpJOlvSmpDJJt8bUpDmRdJKkmZLelXRNonxJYr+fpLGSvgscC4yK995L0t6SXpA0XdLbsUySRsV7zpTUP96nRNLLkh6R9IGkkZIGRK0zo8EJknaSNF7SW3E7dNN/7Y6z+XHOOedw7bXXUq/e2j+77du3Z+LEiQCMGzeOWbNmFUueU4fwHnfl7AOcZGa/kPQI8GPgIoIxx8uShhPSi54T639jZodHR68JQBfgc+BjSaOBnQnZxg41sxWSbgYGAPdkNyypOXBNvMcXwHOSjjezJ3IJNbPXJE0EnjKzR+M93gBGmtnjMU1qPeAEoDPQiWAg8pakyfE2nYD9ouZPCKYjB8XnOTs+543AaDP7u6Q9gGfjNdn6k+5gXNFhZVXfda2zS8PQS0sjadWWVl2QHm2lpaXrHC9ZsoQRI0awYsUKvvzyS8rKyliwYAGlpaUMHjyYq6++mgsvvJBDDz2UevXqrXd9TbJkyZJaba9Q0qoLUqItl/OIbwbBcOPDxPHFhCD970TZXsDbcb+UEJAhvEP9fKLeZEKwPAv4DCiLWzkwLE/7xwH3JI5/Dvwx7i9JlPcDxsb9sUS3LmB7YHaO+44GTk8c30voqZfk0Jx8nifi/tyE/jLgP8D2lX2X7g5WfdKqLa26zNKrbdKkSXbJJZdYixYtrGXLlrbLLrtYw4YNbcCAAevUKy8vt27dutW6tjSSVl1m7g5WF1ie2F8FNM1XMav+6qxrVxNGN0Tw0+4ct30tf5ayysxsk8Ye2+apk+/6yu6brTn5PJnRmXoEQ5TMM7Qwsy8ruafjbPGMGDGC2bNnU1FRwUMPPcT3vvc97rvvPubOnQvA6tWrufrqqxk8eHCRlTp1AQ/c1WMR8IWkw+LxKcDL1bj+RaCfpJ0BJDWT1DJP3TeAIyTtGOfBT0q09T9J+0mqByTf0f6S0NPGzBYDsyUdH9vaRlIjQk+6v6T6knYi2IW+WY1neI4wckC8b+dqXOs4ToIHH3yQNm3a0LZtW5o3b86gQYOKLcmpA/gcd/U5DbglBsFPCNabBWFm70u6jDBfXQ9YAZxJcNrKrjtH0m8IXtgC/mZmE+LpSwirx2cRzD4ax/KHgNslDSEMoZ8C3Brn4lcAPyGYghwCTCf03C8ys/9GZ7JCGAL8OZqibEX4IeDdBMcpkJKSEkpKSgAYOnQoQ4cOLa4gp87hgTsPZlYBtE8cX5c4fXCO+iWJ/VISqUGzzj0MPFyghgeAB3KUP0q08cwqfxXIfo87V87yC+OWvLYyzWvOmdl8wgI7x3Ecpwj4ULnjOI7j1CG8x50C4mtb22QVn2JmM4uhx3Ecx0kvHrhTgJl1L7YGx3Ecp27gQ+WO42xRZBt9jBs3jnbt2lGvXj2mTp1aZHWOUzUeuB3H2aLINvpo3749jz322Jqc4Y6TdjxwO46zxZAx+jjjjDPWlO23337su+++RVTlONXD57idGsfdwapPWrWlVResry2XS1fG6OPLLz3Zn1N38cBdB5D0BLA7Ib3pjcBC4GAzOy8agAw1s9bRwetuM+sh6QqgD9AQeA34JdAaGGdmB8b77gM8ZGZd8rTbLba3HSH96ZHAHsBdwNaEEZsfm9mHOa51k5GNIK3a0qoL1teWbQQxZcqUnEYfGRYuXMi0adNYsmQJm5JUmFLkIa3a0qoL0qHNA3fd4HQz+1xSQ+At4GjWJlA5DFggqQXQA3gllt9kZsMBJN0L9DazJyUtktTZzMoIWd/G5mpQ0taERDH9zewtSTsASwlZ0m40s/tjnZy2pGZ2G3AbwB6t97brZ6bvn9r5HVaSRl2QXm1p1QXra6sYULLO+WeffZZp06YxcOBAli1bxuLFi7njjju47777AGjatCldunSha9eum1RXaWnpmkxpaSOt2tKqC9KhLZ3/BzrZDJGUyUm+e9waS9o+7j9AyDl+GPBYrNdT0kVAI6AZ8B7wJHAHMEjSeYQMaAflaXNfYI6ZvQVrcp8jaQpwqaTdgMdy9bazadigPuU5hi2LTWlp6Xp/3NNCWrWlVRdUrW3EiBGMGDFiTd3rrrtuTdB2nLqEL05LOZJKgO8THLk6Ae8QhsynEHrM5YRe9mGEHOSvRu/tmwkWnx2A21nrIjYeOAboDUwzswX5mmZdFzJgTRrWYwm972cl5Uqp6jh1hscff5zddtuNKVOm8KMf/Yijjz662JIcp1I8cKefJsAXZvZ1NALJ5EmfDFwQP98BegLLzWwRa4P0fEmNCYYjAJjZMuBZ4C+Euep8/BNoHue5kbS9pK0ktQY+MbM/AROBjpvoOR2n1igpKeGpp54CoG/fvsyePZvly5fzv//9j2effbbI6hyncjxwp59ngK2iG9fvgNdj+SuEYfLJZraK4BT2dwAzW0joZc8EniDMiye5n9Cbfi5fo2b2DWEofYyk6cDzhB8E/YF3JZUBbYF7NsEzOo7jOAXic9wpx8yWE4a2c6FEvaOyrrsMuCzPdT2AO2PAr6ztt1jfCW1E3BzHcZwi4IF7C0PS48Be5Lb7dBzHcVKOB+4tDDPrm10Wg/meWcUXm5lP9jmO46QMD9xOzmDuOI7jpBNfnOY4zmbDsmXLOOigg+jUqRPt2rXjyiuvBGD69OkccsghdOjQgT59+rB48eIiK3WcDccDt+M4mw3bbLMNL730EtOnT6esrIxnnnmG119/nTPOOIORI0cyc+ZM+vbty6hRo4ot1XE2mBoL3JJaSXq3pu6/MUgaLun7cf8cSY2qqD9M0gWbsP2/SWoa93MmRpY0VlK/XOequPdgSafG/YGSmldRf6Ckm6rbjuOkEUk0btwYgBUrVrBixQokUV5evsa2s1evXowfP76YMh1no9gi57jN7IrE4TnAfcDXtdj+D2vw3rckDgcC7wKf1VR7heDuYNUnrdrSpCuX+xfAqlWr6NKlCx999BFnnnkm3bt3p3379kycOJHjjjuOcePGMWvWrFpW6zibDpmtl9Vy09xYagU8TUgK8l3gP8BxhBzYtxByaH9MMND4QlIpIQNYF2An4FTgN0AH4OH4XjKSTgaGENyp3gB+ne995NibvZWQVewL4KdmNk/SWOApoDlwHSFt6Hwz6ynpB8AfCOYZ883sSEnDCK5YrePnDTFzWK42LwKWmdmfJI0GOpnZ9yQdCQwys5MlVQBdzWy+pCVm1liSgDGE17Q+JbyjfaeZPZqnnQqCCUjPWPQzM/soal0CVBAMRP5DSE96CNCe9d2+fkxIYdqI8JrY42Z2UWzjKOAqYBvCf6tBZrZE0sh4zUrgOTNbbzQiyx2syxU33J7rMYrKLg3hf0uLrSI3adWWJl0dWjRZ53jJkiVretuZ48svv5whQ4ZQv359xowZw6JFizj00EN57LHHmDBhQq3ozNaVJtKqLa26oHa19ezZc5qZre96Y2Y1sgGtCH/YO8fjR4CTgRnAEbFsOCEIApQC18T9oYRe4q6EoDEb+DawH8Eoo0GsdzNwaiUaDBgQ968gOGZBCGj94n4FsGPc34mQgWzPeNwsfg4jWGNuA+wILMhoyNHmwQTrTAjZzd4EGgBXAr/M0eaS+HkCITtZfcIPioUZjXnaqQAujfunAk8ltF6Q+E67xv2tgU+AbvF4B8KIy8BY3oSQGe1fhIxsOxLSqW4X618cv8NmhB86mR99Tav6t9CmTRtLI5MmTSq2hLykVVtadZnl1jZs2DAbNWrUOmXl5eXWrVu3WlJV976zNJBWXWa1qw2Yajn+ptb04rRPLdhHAkwj9OiamtnLsexugqtVhonxcybwnpnNsZA57BNCMDmS0CN/K6bcPJLQC87HakKvFMJweI8q9B5MSCH6KYCZfZ4491czW25m84G5wC557jEN6BKdu5YTzEC6EkxAXslzDYTv4UEzW2VmnwEvVaEV4MHE5yFV1F3P7cvMMubFL5rZIgt5zN8HWhK+i/0JpiVlwGmxfDGwDLhD0gnU4hSD41TFvHnzWLhwIQBLly7lhRdeoG3btsydOxeA1atXc/XVVzN48OBiynScjaKm57iXJ/ZXAU0LrL8669rVBK0C7jaz32ygnqrmBXI6YmVpg/AsOb87M1sRh7EHEXrpMwjD2QMzb5YAACAASURBVHsB/9hIfZXV39TPJuB5MztpvRtJBxF+NP0UOAvPwuakhDlz5nDaaaexatUqVq9ezYknnkjv3r258cYb+fOf/wzACSecwKBBg4qs1HE2nNpenLYI+ELSYWb2CnAK8HIV1yR5EZggabSZzZXUDNjezP6Vp349gjPWQ8DPiCYcWXwJbA/MJ/SO/yxpTzP7VFKzrF53oWScu04njB78kWChWVlwnQz8UtI9wM6EYP9AFe30B0bGzyk5zmeeDRJuX2b2VhwRqGy28nXCd7G3hbnzRsBuhCmMRmb2N0mvAx9VodFxao2OHTvyzjvvrFc+dOhQhg4dWgRFjrPpKcaq8tOAW2Ig+ITQMy0IM3tf0mXAc5LqASuAMwnzsrn4CmgnaRrhR0P/HHVuA56WNMfC4rT/BzwW7z8X6FWovgSvAJcCU8zsK0nLqHyYHOBxQs91JvABhf2g2UbSG4QfKOv1jAlz+bdIyixOy7h9NSQE7e/nu7GFRXwDgQclbROLLyP8GJgQPb8FnFuATsdxHGcTUWOB28wqCKuYM8fXJU5nO05hZiWJ/VLCwqpc5x5m7bx1ITouBy7PKhuY2B9DWM2dOX6asBo+WX9Y1nF7KsHMXiQsSMsct8k63yqx3zh+GmHYuTr82cyuyqfVzMYDyRdWc7l9jY1b5preif2XgG452j2omjodx3GcTYRnTnMcx3GcOkS1e9ySvgXsbmYzakDPBhGHi7fJKj4l05utoTa/TZhzz+ZIM1uwCdvJ59zValO14TiO49QdCgrcMTnKsbF+GTBP0stmdl4NaisYM+tehDYXAJ1roR137nKcPCxbtozDDz+c5cuXs2jRIk477TSuuuoqysrKGDx4MMuWLWOrrbbi5ptv5qCDfIbH2TwodKi8iZktJiQJucvMulDJwibHcZzaIGkqcscdd6wxFbnooou48sorKSsrY/jw4Vx00UXFluo4m4xCA/dWknYFTiSkCq3TFNuIQ9IdkvaP+xWSdsxRZ4OMTSQdK+mSuH98pp1K6pdIqvP/TZ0tk6SpyMqVK9eYikhaY925aNEimjev9H9xx6lTFDrHPRx4Fng1vgPcGviw5mTVLFZkIw4zO6MG7z2RtRnojif80Hq/ptorBDcZqT5p1VZMXVWZipSXlzNkyBC6d+/ODTfcwNFHH80FF1zA6tWree2112pZrePUHDVmMrJOI9IThJSl2xJMLhYCB5vZeZKGAkPNrLWkvQiZ0XpIugLoAzQkZCD7JSG96TgzOzDedx/goTh0n6vdCmrYiCNHmycW8GylhHziU7MMRy4l5B2fBcwjJG25Lk87pYT1BgcR8o6fbmZvxnevuxKStzxFeH99UXwGEQxediJkSPtJ/O8yjJCApj0hZevJZmaSuhCSxzSO5wea2RxJQ4DBhFz075vZT3Poc5ORjSCt2oqpK9tUJJv//ve/XHPNNQwZMoQnn3ySTp06ccQRRzBp0iSeeuoprr/++lpSui5umFF90qoL0mEyUujitDbAX4BdzKy9pI7AsWZ2dYHtn25mn8fEH28BRwMXxnOHAQsktSDkEs8kKrnJzIbH9u8FepvZk5IWSeocc6APIvEOch4Wm9lBcWj8BiD5nvKjks5ibRDdmhDo+8eRhR1Ym12sM3AAIZiXSxpjZrm8AScX8GzrEYPkT2MbWwFvE4JoZWxnZt+VdDhwJ+u+N/+apIkE85FHYxtvACPN7PGYQKUeIXAfALQjjDq8Chwa644BjovJWPoDvydkg7uEYMSyXNFXPBszu42Q3IY9Wu9t189Mn4Ps+R1WkkZdkF5txdRVMaCk0vOlpaUcf/zxLFiwgBdffJHx48cjiSOOOILRo0dTUlL59TVFaWlp0dquirRqS6suSIe2Qv8PvJ0QjG4FMLMZkh4ACg3cQyRlVkfvHrfGMe3m7oTe4eGEQPdYrNczWmQ2IjhSvUdwBrsDGCTpPEImsKqWiiaNOEZXUXc9Iw4I82hEI454nDHiWC9wm9l/JVX1bLk4jNCT/zq2MbGSuus8m5lNlrRDviAa77c90MLMHo/XLEs825tmNjselxGc3RYSfgg8H+vUB+bE280A7o8jKU9UJbJhg/qU5xnmLCalpaVVBoNikVZtadM1b948GjRoQNOmTVm+fDkvvPACF198Mc2bN+fll1+mpKSEl156iX322afYUh1nk1Fo4G4Uh2GTZSvzVU4iqYSwAv0QM/s6DvFuS8itPYhgEfkKoSd3CHB+7A3eTBhCnhWHtreNtxxPsMh8iTCUXNU70zVpxJGPvM9WRfsbYzJS1fWq5Fw+k5H3zCyX69iPCD9GjgUul9Qu4TTmOLVG0lTkyy+/ZNCgQfTu3ZumTZsydOhQVq5cybbbbsttt91WbKmOs8kodFX5/DhHawCS+rG291UVTYAvYtBuy9qUmxkjjsnAO4R56OWxV5sJ0vMlNSYYhQBreorPEobu7yqg/f6Jz4KNOCD0UiVtyLhgZc9W2TV9JTWMveM+BbTTP+rsASzKcf81zxZHD2ZLOj5es03MF5+PcmAnSYfE+g0ktYs53Hc3s0nARQTHt3RORjmbPRlTkRkzZnDXXXdxxRVXANCjRw+mTZvG9OnTeeONN+jSJecyGMepkxQalM4kzFe2lfQf4FNgQIHXPgMMljSDEAxej+WvEIaSJ5vZKkmzCIETM1so6XaC4UYFYV48yf2Ed8qfK6D9GjPiqIS8z5YPM3tb0sOEBWf/ompTEghOa68RF6flOP8QcHtcTNaP4MZ2q6ThBIOWn1Si55v4A+1PkpoQ/q3cQDBAuS+WCRhtZgsL0Oo4juNsAqoM3LGH1dXMvi9pO6CemX1ZaANmthw4Jt/tE/WOyrruMoIbVS56AHea2aoCJNSoEUcuzOxjKn+2ksR+q8T+7wkLwAplvGV5k5vZGq1m9iqQ/R53tnf2J6xr6HJWYr+MMCSeTY9qaHQcx3E2IVUGbjNbHVdeP2JmX9WCpkqJubv3Yv0A5DiO4zibPYUOlT8fs3g9TPC4BsDMPq8RVZWQK3d3sYw4lN/cZOYmbOPPwKFZxTcme+2O4zjOlkOhgTszf3pmoswICVGKTrGMOGrD3MTMzqy6luM4jrOlUFDgNrPs3qzjOE6tk3QDW7lyJf369eOqq66if//+TJs2jcaNG7Nw4UKaNm1KWVlZseU6To1QaOa0U3OVm9k9m1aO4zhOfjJuYI0bN2bFihX06NGDY445hocffnhNRqvzzz+fJk0qT4/qOHWZQt/j7pbYDiPktj62hjTVCJJaSXq32DoyFOI4Ft+1fkFSWUw5WhM6mkt6tJLzTSX9uibadpzqknQDW7FixRo3sAxmxiOPPMJJJ+V689NxNg8KHSo/O3kc3+G9t0YUOUkOABqYWeeaasDMPiOR4CYHTYFfEzLZbRDuDlZ90qqtNnVV5Qb20UcfceaZZ9K9+9qlJq+88gq77LKLpzh1Nms2yB1MUgNghpntt+kl1QySWgFPA38HvktwBDuOkJ/8FkJO9I8JhihfxNSs7wBdCG5apwK/AToAD8f3zJF0MjAE2Bp4A/h1vvfLJQ2K95hDSGSy3MzOkrRT1LBHrHoOwTb1tdj2p8CP4/vh2fdcz0UtOnut5+Al6QiC8xmExYWHA98mGJG0l9SOkI1ua8JozI+B38XvqRx4nuAW9jAh6ctWwK/MbL1kMe4OtnGkVVtt6qrKDWzJkiVcfvnlDBkyhD333JMlS5Zw++2306JFC0488cTaEVkA7nRVfdKqC9LhDoaZVbkRzD0yPs9PEZJ2XFPItWnZCMYZK4HO8fgR4GSCYcYRsWw4cEPcL808IzCU4Jy1K+H1r9mEgLdf/G4axHo3A6fmaX9X4N+EQLw1wYXrpnjuAaBH3N8D+EfcLyEE1cqeq1li/16gT9z/DNgm7jdN/Hc8NO43JgTeVsC7sWwMMCDub034MbDmfCw/H7g07tcHtq/qu2/Tpo2lkUmTJhVbQl7Sqi1tuoYNG2ajRo0yM7MXXnjBdt55Z5s1a1aRVa1L2r6zJGnVllZdZrWrDZhqOf6mFvo6WNITeiXwL4tuUnWMTy1kA4NgmbkXIai9HMvuBsYl6mccumYSDDfmAEj6hJDStAehR/5WnGdrCMzN03Z3oNTM5sV7PAy0iee+D+yfmKvbIeYrL4R8Lmq5HLxeBf4o6X7gMTObnWUcMwW4VNJu8fyHWechZJa7M466PJH4Ph2nxkm6gS1dunSNGxjAtGnTaNu2LbvttluRVTpOzVLo4rQfmtnLcXs1/sG/pkaV1QzZLlh5bTCz6q/OunY1ax207jazznHb1xLpVHOQb16iHsE9LXOfFlZAWtmEi1o/M+tAsF/NGLT8CPgz4YfFNElbmdlI4AzCD4zXo+nLWnFmDxAWHS4FnpW0XnY6M5tMGGL/D3BvvjcOHKcmmDNnDj179qRjx45069aNXr160bt3yED80ksv+aI0Z4ug0B53L+DirLJjcpTVNRYRjDoOszBPewrwchXXJHkRmCBptJnNldSMMHT8rxx13wBulPRtYDHB4GN6PPcccBYwCkBS5wJ7srlc1B5NOnhJ+jvwM4L/+bctZHWbGV2/2hJMTYjttgY+MbM/xf2OUeP2iTotgf+Y2e0xd/2BgL8W6NQKGTewXFxyySWUlJTUriDHKQKVBm5JvyKsKG4d3b0ybE8Ydt0cOI3gDtaIMHc/qNALzex9SZcBz8VguYKQXW69wG1mc6Kv+BTC4rS3CXPEEBa3/Tl+x1sRLD4HF9B+Phe1+uRw8JL0O0k9CaMN7xMW6+2auGV/4GRJK4D/AsPN7HNJr8ZX6Z4G3gUujHWWEBbtOY7jOLVEVT3uBwh/rEcAlyTKv7Qi5CnfGMysAmifOE7O22e7gWU7eJWyroNW8tzDhFXWhWi4ixwe4mY2n7W+4cnyddrNc898LmrrOXhZ1mt9kQri92JmIwj/rbOv+1lW0d2VaXIcx3FqjkoDt5ktIgwnnwQgaWfC8GxjSY3N7N81L9FxHMdxnAyFpjztQ3h/tzlh1XRL4B9Au5qTVnepCdewShzQnt3QezqO4zh1j0IXp11NGE5+wcwOiPOkvnwzD1YDrmFWJAc0x3EcJ10U+jrYCjNbANSTVM/MJgE1lobTcZwtk2XLlnHQQQfRqVMn2rVrx5VXXgnAsGHDaNGiBZ07d6Zz58787W9/K7JSxykehfa4F8bXjV4hJPWYS0jE4iSQNBj42szukTQQeM5CLvB89QcCXc3srFqSuEmJaWSfMrP2VVR1nILI5/4FcO6553LBBRcUWaHjFJ9CA/dxhKQc5wADgCaE9KBOAjO7JXE4kPDqVN7AvbFIqm958qKnCTcZqT5p1bapdWUbiVTl/uU4ToFD5Wb2FSHFZ4mZ3Q3cAXxTk8IKQdITkqZJek/S/5N0oqQ/xnNDY2pSJO0VE5Eg6QpJb0l6V9JtCuwl6e3EffeRNK2SdiskXSPpzbjtHcuHSbpAUj+gK2F0okxSQ0ndJL0maXq8JpPUpLmkZyR9KOnaRBtHSZoi6W1J4+KIR6btK+Lz/ETSEEnvS5oh6aFKNA+TdEHi+F0Fq9PtJP016npX0T5UUhdJL8fv91lJuybKp0uaQnhn3XE2KatWraJz587svPPO9OrVa43710033UTHjh05/fTT+eKLL4qs0nGKR0HuYJJ+QXB6amZme0naB7jFzI6saYFV6GoWE4Q0JCQfOZqQP7ubgsd0S+B4Qi7wtmb2m8w18fp7gUfM7ElJk4BzzaxM0h+AOWY2Jk+7FcDtZvb7mPLzRDPrHROsLDGz6xTcxS4ws6mStgb+CfQ3s7ck7QB8TTA5uYJg37mc4MDVgzC68RhwjJl9JeligmHI8Nj2zWZ2bdTyGbCnmS2X1NTMFubRvEZbPH4X6E1IifoDM/tFLG8Stb0MHGdm82IwP9rMTo9JYs42s5cljYoa1xsql7uDbRRp1bapdVXmAJZ0/2rSpAlNmjRBEnfeeScLFixYk6M8WT+NjlJp1QXp1ZZWXVC33MHKCG5R7yTKZhZybU1uwDBCSs7phPfNDya8prY9IcXouYTV73cQ8q1DsKp8g5Bt7D/AJbF8AMHysj7B3vPblbRbAbSO+w2ABQk9F9had7Gucb8D8GqO+wwk/ADIHD9NCNy9gfnxey8jZDn7v0TbLRPXPAM8SvgR0LiK7+qCxPG7BOevNgTb0GuAw+K59oS0rJn2ZxLSsjYB/p24R0cSzmH5NncHqz5p1VbbupLuXxk+/fRTa9eu3Xp1/TurPmnVllZdZulwByt0VflyM1szNC5pK/IbZtQKkkoIPelDzKwTwTt7W0JK0UGE3usrwGHAIcCrqtyUYzwh/3pvYJqFVfSVYXn2c8qtpE628UnGvOR5W2s6sr+Z/TxR76vE/npmInnaWcm6UyPbApjZB/HamcAIBX9vEdzQMu13MLOjqngOx9lo5s2bx8KFYdAo4/7Vtm1b5syZs6bO448/Tvv2vh7S2XIpNHC/LOm3QENJvQjWl0/WnKyCaAJ8YWZfK7hcZdKWTgYuiJ/vAD0JPzwWkduUAwAzWwY8C/yFHGlJc9A/8Tklx/kvWWvO8U/CXHY3AEnbVxJgAV4HDk3MnTeS1Ca7khJmIsBFBLezfGM4FQRDECQdSEzmIqk5YSX8fQT71gMJP3p2UjAiQVIDSe0sDMMvkpRJpzqgkmdwnGqTz/3roosuokOHDnTs2JFJkyYxevToYkt1nKJR6KryS4CfE3plvwT+Rhh+LibPAIPjnGs5IdhB6GXvDkw2s1WSZhECZ2WmHBnuB04gDAtXxTYKGdLqkTsZzViCeclSQo+/PzAmzscvJYwW5MTCvPJA4EFJmQxslwEfZFXNaSaS57bjgVMllRGeO3OvDsAoSasJJim/MrNv4gK7P8V7bwXcQPD6HkTw4/6a8EPHcTYZ+dy/7r333iKocZx0UpU72B5m9m8zW00YVk7NCiMzW04Y2s6FEvWOyrounykHhPnlO62wV6z+bGZXZd17WGJ/PCFYZniL9c1MxsYtc03vxP5LQLfsRs2sVWJ/BTnMRHJhZkuBo3KcqiBHALZgK3p4jvJpQKdE0bBC2nccx3E2DVUNlT+R2ZE0vrKKdR2FXOCnEhaoOY7jOE4qqWqoPJn5oHVNCik2liMXuPIbe7SqFVEbgKRBwNCs4lfNzN+5dhzH2QyoKnBXZ+X0ZkeuYJ52LI/nt+M4jrN5UNVQeSdJiyV9CXSM+4slfSlpcW0IdBxny8FNRhynairtcZtZ/doS4jiO4yYjjlM1hb7H7WwAMRf4u0XWUCFpZswv/pyk7yTOHSDJJB2ddc2lCvnfZyjkWu8ey7eWdIOkj2Nu9QmSdqvtZ3I2X+QmI45TJYW+x+3UbXqa2fyYg/23wJBYfhLw9/j5LEBMutIbONBC/vMdCeluAf5ASCrTJr4jPwh4TFL3mJ4vJ+4OVn3Sqq2m3cEgmIx06dKFjz76iDPPPJPu3bvz9NNPc9NNN3HPPffQtWtXrr/+er71rW9tMh2OU5coyGTE2TAU/KqfJgTH7xJyox8H7AvcAjQi5EU/3cy+iMYk7xBSkO5EeD3tN4QkKQ/Hd9CRdDIh+G5NyLv+63zvnkdTkq4xcP8AGGJmP1ToxnwM9CIkrWltZssknQAMMrM+WfdpBMwiGJosTpS/Agwzsxez6rvJyEaQVm1uMlJ90qoL0qstrbogHSYj3uOuefYBTjKzX0h6hGBychFrHbaGA1cSvM4BvjGzwyUNBSYQgvjnwMeSRgM7E7KwHWpmKyTdTEg9ek8BWnoTssYBHAp8amYfxx8MPyQ4kj0HXCHpA+AFwg+Gl4G9CQYj2YsSpwLtgHUCt5ndBtwGsEfrve36men7p3Z+h5WkURekV9um1lUxoKTS89OmTWPBggUMGjRoTVnr1q3p3bs3JSXrXltaWrpeWRpIqy5Ir7a06oJ0aEvfX4bNj09jFjKAacBeQNMYDAHuJuR+zzAxfs4kGH3MAVDwFt+dkCmtC/BWnPtrCMytQsMkSauAGazNGncSkPHvfgg4BXjMzJZI6kIwZ+kJPCzpEsJIQK7hmSqNRxo2qE95jiHRYlNaWlpl4CgWadVW07rmzZtHgwYNaNq06RqTkYsvvpg5c+aw6667Am4y4jgeuGuebPevpgXWX5117WrWOofdbWa/qYaGnmY2P3MgqT6h53+spEvjPb8taXsz+zIOu5cCpZJmAqcRfly0zNRJ3PtAim8442wmzJkzh9NOO41Vq1axevVqTjzxRHr37s0pp5xCWVkZkmjVqhW33nprsaU6TtHwwF37LAK+kHSYmb1C6Om+XMU1SV4EJkgabWZzJTUDtjezf1XjHt8HppvZmtXkku4Gjpf0JrDazD6MpzoD/zKzr2KdP0oaHBennUqYp3+pGm07Tl7cZMRxqsYDd3E4jeAc1gj4hOC4VRBm9r6ky4Dnoq3nCuBMoDqB+yTg8ayy8cCvgPcJLmZNCR7eHxEXmREWyl0HfBDdxP4J9K1sRbnjOI6zafHAXYOYWQXQPnF8XeJ0tlMYZlaS2C8lDFfnOvcw8HCBGlrlKBuYo2wia+fXv5vnXsuBs+PmOI7jFAFPwOI4juM4dQjvcW8mSHoD2Car+BQzm5mrvuM4jlM38cC9mWBm3YutwXEcx6l5fKjccZyikc8NLMN1112HJObPn5/nDo6z5eE9bsdxikY+N7CDDz6YWbNm8fzzz7PHHnsUW6bjpAoP3LVIzF3+lJnVubRPksYStD+azH9eyLVuMlJ90qptY3Vlm4pU5gZ27rnncu2113LcccdtuGDH2QzxoXLHcYrKqlWr6Ny5MzvvvDO9evWie/fuTJw4kRYtWtCpU6diy3Oc1OHuYLVIsd3CJJ0IHGxm50UTk6Fm1lrSXoQ0qj0kXQH0IeRAfw34pZlZrh438BUhkct4M7s9qy13B9sI0qptY3UV4gZ21llncd111zFq1CgaN27MT3/6U2699VaaNMl/beb6NDpKpVUXpFdbWnVBOtzBMDPfamkDWhGykXWOx48AJxPMP46IZcOBG+J+KXBN3B8KfAbsSnjtazbwbWA/Qq7wBrHezcCpedr/DvBW3H8UeAtoQcjkNiKWN0vUvxfoE/fHAv3ifkV8lhfytZXc2rRpY2lk0qRJxZaQl7Rqq2ldw4YNs+HDh9tOO+1kLVu2tJYtW1r9+vVt9913tzlz5hRV24aSVl1m6dWWVl1mtasNmGo5/qb6UHnt86lV7RZ2eKL+em5hFjKYZdzCjmStW1hZPG6dq2Ez+y/QWNL28doHYluHETy5AXpKeiOai3yPYNmZiwnAXWZWiJ2o4+Rk3rx5LFy4EGCNG9gBBxzA3LlzqaiooKKigt122423336b73znO0VW6zjpwBen1T7FdgubQsiNXk4I1qcDhwDnS9qW0GPvamazJA0Dts1zn1eBYyQ9EH8ZOk61yecG5jhOfjxwF5/adgubTBiOH06YP+8JLDWzRdFYBGC+pMZAP8KQei6uAC4nBPpfVUOv46whnxtYkoqKitoR4zh1BB8qTwenAaMkzSDYaA4v9EIzex/IuIXNAJ4nzIPn4xXCMPlkCwvYZhEWy2FmC4HbCcPyTxDmwCvjHGBbSdcWqtdxHMfZOLzHXYtYOtzCPiYMr2eOj8o6fxnhh0D2dQMT+60Spwq2JHUcx3E2Hu9xO47jOE4dwnvcmynuFuY4jrN54oF7M8XcLcxJIcuWLePwww9n+fLlrFy5kn79+nHVVVdx+eWXM2HCBOrVq8fOO+/M2LFjad68ebHlOk4q8aFyx3FqjYypyPTp0ykrK+OZZ57h9ddf58ILL2TGjBmUlZXRu3dvhg8veH2m42xxeOCuA0hqJendYuvIRlJbSWWS3olpUx2nUvKZiuywww5r6nz11VdrjEYcx1kfHyp3NobjgQlmdmVlldwdrPqkVVt1dWW7gUEwFenSpQsfffQRZ555Jt27h1mdSy+9lHvuuYcmTZowadKkTabZcTY33GSkDpACc5L6wP8RjEUMuJOQee1OQva3D8ysZ9Y1bjKyEaRVW3V1FWIqMmTIEPbcc8815ffffz/ffPMNgwZV703DtBpTpFUXpFdbWnVBOkxGvMddd9gHOMnMfiHpEeDHwEXA2Wb2sqThwJWEpCgA35jZ4dEFbAIhiH8OfCxpNLAz0B841MxWSLoZGADkyj3eGWhh0UdcUlMzWyjpFmBJ1vvoAJjZbcBtAHu03tuun5m+f2rnd1hJGnVBerVVV1fFgJJKz0+bNo0FCxasE6T33HNPfvSjH3H33XdXS1tpaSklJZW3VwzSqgvSqy2tuiAd2tL3l8HJRyHmJOMS9dczJwGQlDEn6cFacxIINp5z87T9CdBa0hjgr8Bz1RHesEF9ynMMmRab0tLSKgNLsUirto3VNW/ePBo0aEDTpk3XmIpcfPHFfPjhh+yzzz4ATJw4kbZt224ixY6z+eGBu+5QNHOSOPzeCTgaOBM4kWBO4jjVIp+pyI9//GPKy8upV68eLVu25JZbbim2VMdJLR646y61Zk4iaUfC0Pt4SR8TvLkdp9rkMxUZP358EdQ4Tt3EA3fd5jTgFkmNCMPZBa/mMbP3JWXMSeoBKwi96VyuYi2Au2I9CAvdHMdxnCLggbsOUGxzEjObDhyYo3xYVdc6juM4mxZPwOI4juM4dQjvcTvr4OYkjuM46cYDt7MObk7iOI6Tbnyo3HGcWmPZsmUcdNBBdOrUiXbt2nHllSFb7uWXX07Hjh3p3LkzRx11FJ999lmRlTpOevHA7ThOreHuYI6z8XjgdqqFpLGS+hVbh1M3cXcwx9l4fI7bqXHcHaz6pFWbu4M5TvFxd7A6gKQnCPnFtwVuBBYCB5vZedFEZKiZtY6e2HebWQ9JVwB9CDnIXwN+CbQGxpnZgfG++wAPmVmXPO2OBI4FVgLPmdkF4OfLDAAAEHRJREFUksYCy4B2wC7AeWb2VI5r3R1sI0irNncHqz5p1QXp1ZZWXZAOdzDMzLeUb0Cz+NkQeJeQyeytWPYo8FYsOw0Ykbwm7t8L9In7k4DOcf8PBHexnG0SrDszP+6axs+xwDOEaZZ9gNnAtpXpb9OmjaWRSZMmFVtCXtKqbVPrGjZsmI0aNWqdsoqKCmvXrl2177WlfGebkrRqS6sus9rVBky1HH9TfY67bjBE0nTgdULPe3egsaTt4/4DwOHAYcAr8Zqekt6QNBP4HqGHDHAHMCh6bPeP1+ZiMaFnfYekE4CvE+ceMbPVZvYhIdWqWzk5BTFv3jwWLlwIsMYdrG3btnz44Ydr6rg7mONUjs9xpxxJJcD3gUPM7GtJpYQh8ymE3OTlhGB9OnAIcL6kbYGbga5mNkvSsHgNwHiCb/dLwDQzW5CrXTNbKekg4Ejgp8BZhB8AANnzKz7f4hSEu4M5zsbjgTv9NAG+iEG7LWtzk08GhsftHaAnsNTMFknKWH7Ol9QY6EcYUsfMlkl6FvgL8PN8jcbrGpnZ3yS9DnyUOP0TSXcDexLmzcs30bM6mzn/v717j7KqvM84/n1ATUCNFC8sbxEQlcYbaoqoSAZT8FKWSjVVi4maVVNTGzVNjdKICinLZZLm4tI2Sy0BL7Eao4J0VVGSQZMVb1yEIYo3aCCxQhRIRi4K/vrH+44cT+Yw3M7sfeD5rDVr9nn3Puc858zAb/beZ78/dwcz23ou3OX3GHCZpLmkAvlMHn+adJj8qYhYL2kx8DJARKyQdAcwD1hEOgde6V7gr4FpG3ne3UltPz9O6t391Yp1C0gtRHsBl0XEmi1/eWZmtjlcuEsuItYCp9dYrYrthlfd7zrguhr3GwxMiIj1G3neN4GB7Yxf3EFkMzOrIxfuHYykh4GD2XC+2szMGogL9w4mIkZWj+Vi3qdq+JqIeLxzUpmZ2aZy4bZ2i7lZPaxZs4YhQ4awdu1a1q1bx7nnnsvYsWMZM2YMkydPpkuXLuyzzz5MnDiR/fbbr+i4ZqXk67jNrNO4yYjZ1nPh3g5Japa0QNIcSS/l6Ucr1x8jKSSdWjW+Pt/nRUmzJJ2Yx3tLasnLTZJWSpqdH/uGzntl1ujcZMRs6/lQ+fZrVES8IKkn8LqkiRHxXl53AfCL/L3yPPbqiBgAkIv6TcBn2nnspyNihKRdgTmSpkbEzFpB3GRk85U1m5uMmBXPe9x1JOkRSTMlzZf0JUl/I+m7ed2Vkt7IywdL+kVevl7S85JaJN2u5GBJsyoe9xBJNQtlld2Ad4H1+b4iTchyMTA8X6fdnk8Ayzf2wBHxLjCT9Cl1s03StWtX5syZw5IlS3juuedoaWkBYPz48SxevJhRo0Zx6623FpzSrLy8x11fX4yIdyR1I02CcipwdV53MvC2pP1J11W3zTF+a0SMA5B0NzAiIh7Nh6cHRMQc0lSnEzt47nslrSU1Armq4prtk4CFEfF6nj71DOChvK6bpDmk6VH3pYNLxiTtSZrJ7ZvtrKvsDsb1R67rIG7n69Ut7UGWUVmzbW6u5ubmja7v3bs3t912G+edd96HY3369GH06NEMHTp0s7K1trZ2+HxFKGsuKG+2suaCkmRrr/OIv7ZZV68bgRfz10pSkXuJNCvZs6TZyC4gNf44I9/nnLxuHvBb4No8PorU0rMr8Dqw50aet5k0TznA3sCrwEH59m3ApXn5TFKbz7b7tVYsnwDMJ03y0htoyeNN+bXMJu1tX9bR++DuYJuvrNm2NtfSpUtj+fLlERGxatWqGDx4cDz66KPxyiuvfLjNLbfcEuecc06nZ6uXsuaKKG+2suaKKEd3MO9x10lRzUGqRcSyfJj9eElLSH8YnCnpG6SivKek3SPij1X3+5WkvUiFv9rTETFiE98Ksw+5yYjZ1nPhrp9CmoNUk9QdOAb4FukPiRcj4tSK9ZOAs0k9uyvv15+0d/820H1zXrhZLW4yYrb1XLjrp6jmIB9uK2k18DFgYkTMlDQReLhqu58CXyYV7rZz3JD2xi/KGTfxJZuZWb25cNdJFNQcJD9GU43xi9sZmwJMyctda9xvEXBEXm4mnUM3M7MCuHA3CDcHMTMzcOFuGOHmIGZmhgt3Q2uvmJuZ2fbNM6eZWV2tWbOGgQMHcvTRR3P44Ydzww1pevurr76a/v37c9RRRzFy5EhWrFhRcFKzxuDCbWZ1Vasj2LBhw2hpaWHu3Lkceuih3HTTTUVHNWsILtwFquy6VWCG1hrjEyWd29l5bPtTqyPY8OHD2WmndLZu0KBBLFmypMiYZg3D57it7twdbPOVNVtHudrrBga1O4K1mTBhwkfmKzez2pSmQ7UiSOoN/A+pxeaJpLnJzwIOA35ImrHsdVKzkuV52tTZwHGkqUi/AIwGjgTuz9eAI+lC4ApgF9K85/9Q69rvvMf9A2AEsBo4KyLeypO1rAEOB3oB/xQRUyVdDIwkTezSB/hxRIxt53Erm4wcd/3379jCd6l+enWDt1YXnaJ9Zc3WUa4j999jo/dvbW1lzJgxXHHFFfTpky6IuOeee1iwYAHjxo3bqj7cra2tH+7Zl0lZc0F5s5U1F3RutqFDh86MiE9Xj3uPu3iHABdExKWSHiDNJf514CsRMUPSONIc5Vfl7d+LiCGSrgQmk4r4O6Se298D9gHOA06KiPcl/TupQcldNZ5/V+CZiPiGpG8BlwL/mtf1JvXjPhj4uaR+eXwgaUKWVcDzkv47Il6ofNCIuB24HeCTffvFv80r36/a145cRxlzQXmzdZRr0aimDh9j5syZvP3221xyySVMmjSJ+fPnM336dLp337qZdZubm2lq6vj5O1tZc0F5s5U1F5QjW/n+Z9jxLIzUqhM29LbuEREz8tgk4CcV20/J3+cB8yPiTYDc2/tA0uxqx5EKKkA3YOlGnv89YGrF8w+rWPdARHwAvJofv38ef6KtyYmkh/JzfqRwV+q2c1cW1DiEWqTm5uZNKjRFKGu2Lcm1bNkydt55Z3r06MHq1at58sknueaaa3jssce4+eabmTFjxlYXbbMdiQt38dZWLK8HetTasGr7D6ru+wHp5ylgUkSM3sTnfz82nC9Zz0d/J6rPo0QH42Z/olZHsH79+rF27VqGDUt/Kw4aNMhdwcw2gQt3+awElks6OSKeBj4PzOjgPpWmA5MlfS8ilkrqCeweEf+7BVk+l7uH9QH6kpqlHAMMy4+7mtRZ7Itb8Ni2g6jVEey1114rII1Z43PhLqeLgB/mlpxvkPp3b5KI+LWk64BpkroA7wOXA1tSuBeQ/mjoBVyWW4tC+jDd3UA/0ofTah4mNzOzbcuFu0CVXbfy7e9UrB7UzvZNFcvNVHTpqlp3P3D/JmbYrWL5QTb0/754I3dbGhH/uCmPb2Zm25YnYDEzM2sg3uPeQUh6lnTtdaXPR8S8zXmciJgITNxGsczMbDO5cO8gIuL4jrcyM7Oy86FyMzOzBuLCbWZm1kBcuM3MzBqIC7eZmVkDcXcwqztJfyRN5lI2ewG/LzpEDWXNVtZcUN5sZc0F5c1W1lzQudkOioi9qwf9qXLrDAvaa01XNEkvlDEXlDdbWXNBebOVNReUN1tZc0E5svlQuZmZWQNx4TYzM2sgLtzWGW4vOkANZc0F5c1W1lxQ3mxlzQXlzVbWXFCCbP5wmpmZWQPxHreZmVkDceE2MzNrIC7cVjeSTpO0QNJrkq4tOMsESUsltVSM9ZT0hKRX8/c/KyDXgZJ+LuklSfMlXVmibB+X9JykF3O2sWXJlnN0lTRb0tSS5VokaZ6kOZJeKEs2ST0kPSjp5fz7dkJJch2W36u2rz9Iuqok2b6af/dbJN2X/00UnsuF2+pCUlfgNuB04FPABZI+VWCkicBpVWPXAtMj4hBger7d2dYBX4uIPwcGAZfn96kM2dYCp0TE0cAA4DRJg0qSDeBK4KWK22XJBTA0IgZUXO9bhmw/AB6LiP7A0aT3rvBcEbEgv1cDgOOAVcDDRWeTtD9wBfDpiDgC6AqcX3QuACLCX/7a5l/ACcDjFbdHA6MLztQbaKm4vQDYNy/vS5oopuj3bTIwrGzZgO7ALOD4MmQDDiD9p3kKMLVMP09gEbBX1Vih2YBPAAvJH0guS652cg4HflmGbMD+wGKgJ2mysqk5X+Hvmfe4rV7afunbLMljZdIrIt4EyN/3KTKMpN7AMcCzlCRbPhw9B1gKPBERZcn2feDrwAcVY2XIBRDANEkzJX2pJNn6AsuAH+XTC3dK2rUEuaqdD9yXlwvNFhG/Bb4D/AZ4E1gZEdOKzgU+VG71o3bGfO1hDZJ2A34KXBURfyg6T5uIWB/pEOYBwEBJRxSdSdIIYGlEzCw6Sw0nRcSxpNNEl0saUnQg0h7jscB/RMQxwLsUeyrhT0jaBTgT+EnRWQDyueuzgD7AfsCuki4sNlXiwm31sgQ4sOL2AcDvCspSy1uS9gXI35cWEULSzqSifW9EPFSmbG0iYgXQTPqcQNHZTgLOlLQI+C/gFEn3lCAXABHxu/x9Kelc7cASZFsCLMlHTAAeJBXyonNVOh2YFRFv5dtFZ/tLYGFELIuI94GHgBNLkMuF2+rmeeAQSX3yX9LnA1MKzlRtCnBRXr6IdH65U0kS8J/ASxHx3ZJl21tSj7zcjfQf2ctFZ4uI0RFxQET0Jv1e/SwiLiw6F4CkXSXt3rZMOifaUnS2iPg/YLGkw/LQZ4FfF52rygVsOEwOxWf7DTBIUvf87/SzpA/0FZ3LM6dZ/Ug6g3QusiswISLGF5jlPqCJ1JLvLeAG4BHgAeCTpH+kn4uIdzo512DgaWAeG87X/gvpPHfR2Y4CJpF+fl2AByJinKQ9i85WkbEJ+OeIGFGGXJL6kvayIR2e/nFEjC9JtgHAncAuwBvAJeSfa5G5crbupM/E9I2IlXmsDO/ZWOA80tUfs4G/A3YrPJcLt5mZWePwoXIzM7MG4sJtZmbWQFy4zczMGogLt5mZWQNx4TYzM2sgOxUdwMxsS0haT7qMrs3ZEbGooDhmncaXg5lZQ5LUGhG7deLz7RQR6zrr+cxq8aFyM9suSdpX0lO5x3OLpJPz+GmSZin1GZ+ex3pKekTSXEnP5MlnkHSjpNslTQPuyk1Xvi3p+bzt3xf4Em0H5UPlZtaouuXOZZDmlB5Ztf5vSa1lx+f+8N0l7Q3cAQyJiIWSeuZtxwKzI+JsSacAd5F6kEPqET04Ilbnbl8rI+IvJH0M+KWkaRGxsJ4v1KySC7eZNarVuXNZLc8DE3ITl0ciYk6eIvWptkJbMVXlYOCcPPYzSXtK2iOvmxIRq/PycOAoSefm23sAh5B6XZt1ChduM9suRcRTuaXmXwF3S/o2sIL228turA3tu1XbfSUiHt+mYc02g89xm9l2SdJBpL7dd5A6sB0L/Ar4jKQ+eZu2Q+VPAaPyWBPw+xp90R8Hvpz34pF0aO4CZtZpvMdtZturJuBqSe8DrcAXImJZPk/9kKQupF7Kw4AbgR9JmgusYkPbxmp3Ar2BWbnV4zLg7Hq+CLNqvhzMzMysgfhQuZmZWQNx4TYzM2sgLtxmZmYNxIXbzMysgbhwm5mZNRAXbjMzswbiwm1mZtZA/h9OXcPmif1naQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_cutt,max_num_features = 15)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39237\n",
       "1     7720\n",
       "2     1377\n",
       "3      208\n",
       "4       25\n",
       "6        1\n",
       "Name: away_int_walk, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.away_int_walk.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5530943807051336\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "pred_gnb = gnb.predict(X_train)\n",
    "score_gnb = accuracy_score(y_train,pred_gnb)\n",
    "print(score_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6631354157943221\n",
      "0.5662605200351715\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(C=0.05,penalty='l2',max_iter=1000)\n",
    "clf2 = xgb.XGBClassifier()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "eclf = VotingClassifier(estimators=[('lr',clf1),('xg',clf2),('dt',clf3)],\n",
    "                        voting='hard')\n",
    "eclf.fit(X_train,y_train)\n",
    "eclf_preds = eclf.predict(X_train)\n",
    "eclf_score = accuracy_score(y_train,eclf_preds)\n",
    "print(eclf_score)\n",
    "\n",
    "eclf_preds_test = eclf.predict(X_test)\n",
    "eclf_score_test = accuracy_score(y_test,eclf_preds_test)\n",
    "print(eclf_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
